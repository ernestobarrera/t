<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ™ï¸ Audios AEPap 2026 â€” IA como Asistente del Pediatra de AP</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
            background: #0f172a;
            color: #e2e8f0;
            line-height: 1.6;
            padding: 20px;
        }

        header {
            max-width: 900px;
            margin: 0 auto 30px;
            text-align: center;
            padding: 30px 20px;
            background: linear-gradient(135deg, rgba(96, 165, 250, 0.15), rgba(52, 211, 153, 0.15));
            border: 1px solid rgba(96, 165, 250, 0.3);
            border-radius: 16px;
        }

        header h1 {
            font-size: 1.8em;
            margin-bottom: 8px;
        }

        header h1 span {
            color: #60a5fa;
        }

        .subtitle {
            color: #94a3b8;
            font-size: 0.95em;
            margin-bottom: 15px;
        }

        .info-box {
            background: rgba(15, 23, 42, 0.6);
            border: 1px solid rgba(96, 165, 250, 0.2);
            border-radius: 10px;
            padding: 12px 18px;
            display: inline-block;
            font-size: 0.85em;
            color: #94a3b8;
            margin-bottom: 15px;
        }

        .progress-container {
            background: rgba(15, 23, 42, 0.6);
            border: 1px solid rgba(96, 165, 250, 0.2);
            border-radius: 10px;
            padding: 12px 18px;
            margin-top: 10px;
        }

        .progress-bar {
            height: 8px;
            background: rgba(96, 165, 250, 0.15);
            border-radius: 6px;
            overflow: hidden;
            margin-top: 8px;
        }

        .progress-fill {
            height: 100%;
            width: 0%;
            background: linear-gradient(90deg, #60a5fa, #34d399);
            border-radius: 6px;
            transition: width 0.5s ease;
        }

        .block-title {
            max-width: 900px;
            margin: 30px auto 15px;
            padding: 10px 18px;
            font-size: 1.1em;
            font-weight: 700;
            color: #60a5fa;
            border-left: 4px solid #60a5fa;
            background: rgba(96, 165, 250, 0.08);
            border-radius: 0 8px 8px 0;
        }

        .audio-item {
            max-width: 900px;
            margin: 12px auto;
            background: rgba(30, 41, 59, 0.8);
            border: 1px solid rgba(96, 165, 250, 0.15);
            border-radius: 12px;
            padding: 16px 20px;
            transition: border-color 0.3s;
        }

        .audio-item:hover {
            border-color: rgba(96, 165, 250, 0.4);
        }

        .audio-item.done {
            opacity: 0.5;
            border-color: rgba(52, 211, 153, 0.3);
        }

        .audio-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }

        .audio-num {
            font-weight: 700;
            color: #60a5fa;
            font-size: 0.9em;
            background: rgba(96, 165, 250, 0.15);
            padding: 2px 10px;
            border-radius: 6px;
        }

        .audio-name {
            color: #94a3b8;
            font-size: 0.8em;
        }

        .audio-text {
            font-size: 0.92em;
            line-height: 1.7;
            white-space: pre-wrap;
            color: #cbd5e1;
            background: rgba(15, 23, 42, 0.4);
            padding: 12px 16px;
            border-radius: 8px;
            margin-bottom: 10px;
            max-height: 300px;
            overflow-y: auto;
        }

        .audio-actions {
            display: flex;
            gap: 8px;
        }

        .btn {
            border: none;
            padding: 6px 14px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.82em;
            font-weight: 600;
            transition: all 0.2s;
        }

        .btn-copy {
            background: #60a5fa;
            color: #0f172a;
        }

        .btn-copy:hover {
            background: #93c5fd;
        }

        .btn-done {
            background: rgba(52, 211, 153, 0.2);
            color: #34d399;
            border: 1px solid rgba(52, 211, 153, 0.3);
        }

        .btn-done:hover {
            background: rgba(52, 211, 153, 0.3);
        }

        .btn-undo {
            background: rgba(239, 68, 68, 0.2);
            color: #f87171;
            border: 1px solid rgba(239, 68, 68, 0.3);
            display: none;
        }

        .btn-undo:hover {
            background: rgba(239, 68, 68, 0.3);
        }

        .toast {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            background: #34d399;
            color: #0f172a;
            padding: 10px 24px;
            border-radius: 8px;
            font-weight: 600;
            font-size: 0.9em;
            opacity: 0;
            transition: opacity 0.3s;
            pointer-events: none;
            z-index: 100;
        }

        .toast.show {
            opacity: 1;
        }
    </style>
</head>

<body>
    <header>
        <h1>ğŸ™ï¸ Audios <span>AEPap 2026</span></h1>
        <p class="subtitle">IA como Asistente del Pediatra de AP â€” Ernesto Barrera</p>
        <div class="info-box">
            ğŸ”§ OpenTTS.ai Â· Configurar voz, rate y pitch a tu preferencia<br>
            ğŸ“ Archivos: <code>aepap_1.webm</code> â†’ <code>aepap_73.webm</code>
        </div>
        <div class="progress-container">
            <div style="display:flex;justify-content:space-between;font-size:0.85em">
                <span>Progreso</span>
                <span id="progress-text">0 / 73</span>
            </div>
            <div class="progress-bar">
                <div class="progress-fill" id="progress-fill"></div>
            </div>
        </div>
    </header>

    <main id="audio-list"></main>
    <div class="toast" id="toast">âœ… Texto copiado</div>

    <script>
        const audios = [
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 0 Â· PORTADA Y ENCUADRE
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "1", name: "aepap_1.webm", text: `Bienvenidos al seminario "La Inteligencia Artificial como Asistente del Pediatra de AtenciÃ³n Primaria".

Me llamo Ernesto Barrera, soy mÃ©dico de familia en la Comunidad de Madrid, y llevo mÃ¡s de quince aÃ±os trabajando en la intersecciÃ³n entre tecnologÃ­a, formaciÃ³n y prÃ¡ctica clÃ­nica.

Durante las prÃ³ximas dos horas vamos a explorar juntos tres cuestiones que considero esenciales. Primera: dÃ³nde puede ayudarnos la IA hoy, con evidencias reales. Segunda: dÃ³nde puede hacernos daÃ±o si la usamos mal. Y tercera, y quizÃ¡ la mÃ¡s prÃ¡ctica: cÃ³mo interactuar con ella para obtener resultados Ãºtiles y seguros en nuestra consulta.

SerÃ¡ un seminario con elementos prÃ¡cticos. Vais a ver demos en vivo, vais a practicar vosotros mismos, y os vais a llevar herramientas que podÃ©is usar el lunes en vuestra consulta. // EDITADO

Empecemos.` },

            {
                num: "2", name: "aepap_2.webm", text: `Antes de entrar en materia, la declaraciÃ³n obligada: no tengo conflictos de interÃ©s relacionados con este contenido. Las herramientas que mencionarÃ© son de uso personal. No tengo vinculaciÃ³n comercial con ningÃºn proveedor de inteligencia artificial. // EDITADO

Dicho esto, sÃ­ tengo un sesgo que quiero hacer explÃ­cito: creo que estas herramientas tienen un potencial enorme para mejorar nuestra prÃ¡ctica, pero solo si las usamos con el mismo rigor con el que evaluamos cualquier otra intervenciÃ³n clÃ­nica.` },

            {
                num: "3", name: "aepap_3.webm", text: `Al finalizar estas dos horas, serÃ©is capaces de hacer tres cosas concretas.

Uno: identificar escenarios clÃ­nicos donde la IA puede ser Ãºtil en vuestra consulta de pediatrÃ­a. No todos los escenarios son iguales; veremos dÃ³nde el semÃ¡foro estÃ¡ en verde y dÃ³nde estÃ¡ en rojo.

Dos: reconocer las limitaciones y los riesgos mÃ¡s importantes. Porque la IA puede generar informaciÃ³n falsa con una convicciÃ³n que impresiona. AprenderÃ©is a detectar esas trampas.

Y tres: aplicar un mÃ©todo bÃ¡sico de interacciÃ³n, lo que llamamos "prompt", para obtener respuestas clÃ­nicas Ãºtiles. DistinguirÃ©is una instrucciÃ³n eficaz de una que no lo es.

Tres objetivos, dos horas. Vamos a ello.` },

            {
                num: "4", name: "aepap_4.webm", text: `Esta es nuestra hoja de ruta. Cinco bloques, ciento veinte minutos.

Empezamos con un bloque de ruptura, quince minutos, para situar el impacto de lo que estÃ¡ ocurriendo. DespuÃ©s, cuarenta y cinco minutos de fundamentos: quÃ© es la IA, quÃ© dice la evidencia, y quÃ© aplicaciones concretas existen para pediatrÃ­a. A continuaciÃ³n, cuarenta minutos de demos en vivo: verÃ©is las herramientas funcionando en tiempo real. HabrÃ¡ una pausa para cafÃ©. DespuÃ©s, veinticinco minutos de prÃ¡ctica guiada donde vosotros serÃ©is los protagonistas. Y cerraremos con veinte minutos de mensajes clave y evaluaciÃ³n.

PodÃ©is hacer clic en cualquier bloque de la pantalla para saltar directamente si necesitÃ¡is volver a algÃºn punto durante la sesiÃ³n.

Ahora sÃ­, entramos en materia.` },

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 1 Â· RUPTURA (15 min)
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "5", name: "aepap_5.webm", text: `Bloque uno: Ruptura.

Vamos a empezar rompiendo el hielo. Y tambiÃ©n, si me lo permitÃ­s, rompiendo alguna idea preconcebida.` },

            {
                num: "6", name: "aepap_6.webm", text: `Primera pregunta, y quiero que seÃ¡is sinceros.

Â¿CuÃ¡ntos de vosotros habÃ©is usado alguna herramienta de inteligencia artificial esta semana para algo relacionado con vuestra prÃ¡ctica clÃ­nica?

No solo ChatGPT. Cualquier cosa: buscar informaciÃ³n, redactar un informe, preparar una sesiÃ³n, traducir un artÃ­culo...

Levantad la mano si es "sÃ­, regularmente". Â¿Alguna vez? Â¿Nunca?

Perfecto. Guardad vuestra respuesta en la cabeza. Al final del seminario volveremos a esta pregunta y veremos si algo ha cambiado.` },

            {
                num: "7", name: "aepap_7.webm", text: `El treinta de noviembre de dos mil veintidÃ³s, OpenAI publicÃ³ un tuit. DecÃ­a, simplemente: "Introducing ChatGPT."

Nada mÃ¡s. Un tuit, un enlace.

En cinco dÃ­as, un millÃ³n de usuarios. En dos meses, cien millones. NingÃºn producto tecnolÃ³gico en la historia habÃ­a crecido asÃ­.

Ese tuit cambiÃ³ las reglas del juego. No porque la tecnologÃ­a fuese nueva, los modelos de lenguaje llevaban aÃ±os desarrollÃ¡ndose, sino porque por primera vez cualquier persona podÃ­a hablar con una inteligencia artificial. Y eso incluye a nuestros pacientes, a sus familias... y a nosotros.` },

            {
                num: "8", name: "aepap_8.webm", text: `Mirad este grÃ¡fico. Son las publicaciones en PubMed sobre inteligencia artificial y modelos de lenguaje.

En dos mil veintitrÃ©s, era una de cada doscientas quince publicaciones. Hoy, una de cada noventa. El crecimiento ha superado incluso al de los artÃ­culos sobre tratamiento de COVID.

Esto no es una moda pasajera. Es una transformaciÃ³n estructural de la literatura biomÃ©dica. Y como clÃ­nicos, necesitamos saber cÃ³mo navegar este tsunami de informaciÃ³n.

La buena noticia: no tenÃ©is que leerlo todo. Lo que sÃ­ necesitÃ¡is son herramientas y criterios para separar el grano de la paja. Y eso es exactamente lo que vamos a hacer hoy.` },

            {
                num: "9", name: "aepap_9.webm", text: `Voy a contaros dos historias. Las dos son reales.

Historia uno, en verde. Un pediatra necesita dar informaciÃ³n a unos padres sobre gastroenteritis aguda. Usa un modelo de IA para generar un borrador. Lo revisa, lo adapta al caso concreto, y lo entrega. Quince minutos ahorrados. Bajo riesgo, alto impacto.

Historia dos, en rojo. Un modelo de IA sugiere una dosis de medicaciÃ³n. El clÃ­nico no la verifica. La referencia bibliogrÃ¡fica que cita el modelo no existe. Es inventada. Una alucinaciÃ³n.

La diferencia entre estas dos historias no es la herramienta. Es exactamente la misma herramienta. La diferencia estÃ¡ en cÃ³mo, cuÃ¡ndo y para quÃ© la usamos. Y sobre todo, en si verificamos antes de actuar.

Este contraste va a ser el hilo conductor de todo el seminario. Vamos a los fundamentos.` },

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 2A Â· FUNDAMENTOS TEÃ“RICOS (10 min)
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "10", name: "aepap_10.webm", text: `Bloque dos A: Fundamentos.

Antes de hablar de lo que la IA puede o no puede hacer, necesitamos hablar el mismo idioma. AsÃ­ que empezamos con un glosario rÃ¡pido.` },

            {
                num: "11", name: "aepap_11.webm", text: `Seis conceptos que vamos a usar constantemente.

LLM, o modelo de lenguaje grande: es el motor que hay detrÃ¡s de ChatGPT, Claude o Gemini. Predice la siguiente palabra basÃ¡ndose en patrones estadÃ­sticos. Importante: predice, no comprende.

Prompt: la instrucciÃ³n que le das al modelo. La calidad de lo que obtienes depende directamente de la calidad de lo que preguntas.

IA generativa: genera contenido nuevo. No busca en una base de datos; crea texto, imÃ¡genes o cÃ³digo de la nada.

AlucinaciÃ³n: cuando la IA inventa informaciÃ³n falsa con total convicciÃ³n. Es el riesgo crÃ­tico que veremos en detalle.

RAG, o generaciÃ³n aumentada por recuperaciÃ³n: la IA se conecta a fuentes externas y busca antes de responder. Herramientas como Perplexity u Open Evidence funcionan asÃ­. Es mucho mÃ¡s seguro.

Y finalmente, IA agÃ©ntica: la IA que no solo responde, sino que planifica y ejecuta tareas autÃ³nomamente. Es el siguiente nivel, y ya empieza a verse en medicina.

Con este vocabulario compartido, pasemos a ver cÃ³mo encaja la IA en nuestro flujo de trabajo clÃ­nico.` },

            {
                num: "12", name: "aepap_12.webm", text: `La IA puede integrarse en las cinco etapas del flujo clÃ­nico: admisiÃ³n, diagnÃ³stico, tratamiento, documentaciÃ³n y seguimiento.

Una revisiÃ³n sistemÃ¡tica publicada en dos mil veinticinco por Li y colaboradores en Applied Clinical Informatics analizÃ³ hasta quÃ© punto GPT-4 podÃ­a asistir en tareas clÃ­nicas. El resultado: es aplicable al setenta y uno por ciento de las subtareas.

Pero, y esto es clave, "aplicable" no significa "autÃ³nomo." Significa que puede aportar valor si un clÃ­nico supervisa. Veremos exactamente dÃ³nde sÃ­ y dÃ³nde no a lo largo de la sesiÃ³n.` },

            {
                num: "13", name: "aepap_13.webm", text: `Esto es lo que necesitÃ¡is entender de verdad sobre cÃ³mo funciona un modelo de lenguaje.

Un LLM es un sistema que predice la siguiente palabra basÃ¡ndose en patrones estadÃ­sticos de billones de textos. Genera texto coherente: sÃ­. Comprende lo que dice: no. Razona lÃ³gicamente: no.

Â¿Por quÃ© es importante? Porque de aquÃ­ se deriva el riesgo mÃ¡s importante: puede generar informaciÃ³n completamente falsa con una confianza absoluta. Eso es lo que llamamos alucinaciones. Y lo veremos en detalle en el bloque de evidencia, que empieza ahora.` },

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // EVIDENCIA CIENTÃFICA
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "14", name: "aepap_14.webm", text: `Dejemos las opiniones a un lado. Vamos a ver quÃ© dice la literatura reciente. Porque en este campo, lo que era cierto hace seis meses puede haber cambiado.

La sÃ­ntesis que vais a ver se basa en una revisiÃ³n de mÃ¡s de quinientas referencias publicadas entre dos mil veinticinco y dos mil veintisÃ©is.` },

            {
                num: "15", name: "aepap_15.webm", text: `El modelo Human-in-the-Loop define cÃ³mo debe funcionar la colaboraciÃ³n. La IA propone, redacta, sintetiza. El pediatra verifica, decide, empatiza. Son roles complementarios, no intercambiables.

En el Ãºnico ensayo clÃ­nico aleatorizado publicado hasta la fecha, Goh y colaboradores probaron esto con 1213 consultas reales. Los mÃ©dicos con GPT-4 mejoraron un 6.5% en manejo clÃ­nico. Pero tardaron 2 minutos mÃ¡s por caso. En una agenda de treinta pacientes, eso son sesenta minutos adicionales.

El mensaje no es "Ãºsalo siempre". Es "Ãºsalo donde el beneficio justifique el coste". En documentaciÃ³n, casi siempre. En diagnÃ³stico de rutina, rara vez. Esa decisiÃ³n estratÃ©gica es exactamente lo que veremos con el Modelo SÃ¡ndwich al final.` },

            {
                num: "16", name: "aepap_16.webm", text: `El paradigma de colaboraciÃ³n se resume asÃ­: por separado, mÃ©dico e inteligencia artificial tienen capacidades complementarias pero asimÃ©tricas.

El mÃ©dico aporta juicio clÃ­nico, empatÃ­a y contexto del paciente y su familia. La IA aporta velocidad y procesamiento masivo, pero con una precisiÃ³n global del 52.1% segÃºn el meta-anÃ¡lisis de Takita con ochenta y tres estudios. Traducido: acierta uno de cada dos diagnÃ³sticos. Es el nivel de un mÃ©dico no especialista.

En la intersecciÃ³n, Wang muestra una mejora de casi 5 puntos en manejo clÃ­nico. Juntos, mejor. Pero la combinaciÃ³n solo funciona cuando el humano mantiene su criterio activo, no cuando se limita a dar "ok" a lo que la mÃ¡quina propone. Esa diferencia entre supervisar y cuestionar es el tema de la siguiente diapositiva.` },

            {
                num: "17", name: "aepap_17.webm", text: `AtenciÃ³n a la paradoja mÃ¡s contraintuitiva de toda la sesiÃ³n. Wang y colaboradores, en npj Digital Medicine, muestran que Humano mÃ¡s IA no siempre supera a la IA sola.

El riesgo relativo es de 1.59 pero no significativo. Los errores persisten entre el 26 y el 36 por ciento incluso con supervisiÃ³n. Y el intervalo de predicciÃ³n va de menos 31 a mÃ¡s 41 puntos, una incertidumbre que hace imposible predecir el resultado caso por caso.

Â¿Por quÃ© ocurre esto? Porque supervisar no es lo mismo que cuestionar. Cuando leemos una respuesta bien redactada, nuestro cerebro tiende a aceptarla. Es el mismo sesgo de anclaje que conocemos en clÃ­nica, pero amplificado por la elocuencia de la mÃ¡quina.

Pero hay una excepciÃ³n: en el ensayo de Goh, mÃ©dicos con formaciÃ³n especÃ­fica mejoraron un 6.5 por ciento. La clave: integraciÃ³n con mÃ©todo, no supervisiÃ³n pasiva. Y atenciÃ³n al deskilling: si un residente delega sistemÃ¡ticamente los diagnÃ³sticos diferenciales a ChatGPT durante cuatro aÃ±os, Â¿quÃ© ocurre el dÃ­a que no tiene cobertura? Esa pÃ©rdida de competencia es acumulativa y silenciosa.` },

            {
                num: "18", name: "aepap_18.webm", text: `Antes de seguir con mÃ¡s datos, quiero que nos paremos un momento. La paradoja que acabamos de ver no es solo un dato acadÃ©mico. Toca algo muy personal.

Â¿Alguna vez hemos confiado demasiado en una herramienta sin verificar? No hablo solo de IA. Â¿CuÃ¡ntas veces hemos aceptado una calculadora de dosis sin comprobar la fuente? Â¿CuÃ¡ntas veces hemos seguido una guÃ­a que luego descubrimos que estaba desactualizada?

La respuesta honesta es que sÃ­, nos pasa. Y con la IA el riesgo se amplifica porque la respuesta viene envuelta en un lenguaje impecable. No tartamudea, no duda, no dice "no lo sÃ©". Y eso activa el mismo sesgo de anclaje que conocemos en clÃ­nica.

Esa autorreflexiÃ³n es el mejor escudo. Ahora vamos a ver la evidencia especÃ­fica que necesitÃ¡is para calibrar exactamente dÃ³nde confiar y dÃ³nde dudar.` },


            {
                num: "20", name: "aepap_20.webm", text: `Hablemos de nÃºmeros concretos. El meta-anÃ¡lisis mÃ¡s amplio publicado hasta ahora, Takita y colaboradores, ochenta y tres estudios, muestra que la precisiÃ³n diagnÃ³stica global de la IA es del 52.1%. Uno de cada dos. Eso es el nivel de un mÃ©dico no especialista, y queda 15.8 puntos por debajo del experto.

Ahora bien, esa cifra global esconde una asimetrÃ­a importante. En tareas acotadas, cribado de artÃ­culos, extracciÃ³n de datos estructurados, codificaciÃ³n, el rendimiento es alto. Pero en diagnÃ³stico complejo, donde hay que integrar historia, exploraciÃ³n y contexto familiar, la IA no llega.

Pensadlo asÃ­: si un padre os pregunta "Â¿puedo fiarme del diagnÃ³stico que me ha dado ChatGPT?", la respuesta honesta es "acertarÃ¡ la mitad de las veces, y no sabrÃ¡s cuÃ¡l mitad." Esa incertidumbre es exactamente lo que justifica que la IA sea copiloto, nunca piloto.` },

            {
                num: "21", name: "aepap_21.webm", text: `Las alucinaciones son el riesgo mÃ¡s crÃ­tico. Y se manifiestan en dos contextos distintos.

Primero, las bibliogrÃ¡ficas: hasta el 91.4% de las citas de Bard eran fabricadas. GPT-3.5, el 39.6%. GPT-4, el 28.6%. Nunca hagÃ¡is bÃºsquedas bibliogrÃ¡ficas ciegas con estos modelos.

Segundo, en documentaciÃ³n clÃ­nica: un framework de Asgari y colaboradores con 50 mÃ©dicos y casi 13 mil frases anotadas mostrÃ³ que las alucinaciones se pueden reducir al 1.47%, por debajo del nivel humano. Pero las omisiones, lo que el modelo olvida incluir, alcanzan el 3.45% y son el riesgo mayor.

La regla de oro sigue siendo la misma: verificar siempre antes de usar. Nunca copiar y pegar sin comprobar el DOI o el PMID en la fuente primaria.` },
            {
                num: "22", name: "aepap_22.webm", text: `Esta brecha es crucial para entender los titulares. Los modelos de lenguaje obtienen entre 84 y 90 por ciento en exÃ¡menes teÃ³ricos tipo USMLE. Impresionante. Pero recordad la cifra que acabamos de ver: en clÃ­nica real, 52.1%.

Â¿Por quÃ© esa diferencia tan brutal? Porque un examen tiene una respuesta correcta entre cinco opciones predefinidas. La clÃ­nica real tiene ruido: un niÃ±o que llora y no se deja explorar, unos padres que olvidan mencionar que el abuelo tiene celiaquÃ­a, una otoscopia con cerumen que no te deja ver. Eso no aparece en los datasets de entrenamiento.

Y el dato mÃ¡s preocupante: solo el 9.4 por ciento de los estudios publicados evalÃºan errores y seguridad. Es decir, estamos entusiasmados con una herramienta cuya tasa de daÃ±o apenas se ha medido. Con un fÃ¡rmaco no lo aceptarÃ­amos; con la IA tampoco deberÃ­amos.` },

            {
                num: "23", name: "aepap_23.webm", text: `Esto me preocupa especialmente como clÃ­nico. No por nosotros, sino por lo que hacen nuestros pacientes cuando no estamos.

Un estudio publicado en The Lancet Digital Health encontrÃ³ que el ochenta y nueve con cinco por ciento de las respuestas de modelos de IA sobre primeros auxilios y reanimaciÃ³n cardiopulmonar en niÃ±os contenÃ­an errores significativos o alucinaciones.

Pensad en la escena: una madre a las tres de la maÃ±ana, el niÃ±o de dos aÃ±os se ha atragantado con una uva, pÃ¡nico. El mÃ³vil estÃ¡ ahÃ­, y la primera reacciÃ³n es preguntar a ChatGPT "quÃ© hago si mi hijo se atraga." La respuesta puede sonar impecable. Puede describir la maniobra de Heimlich con detalle. Y puede estar completamente equivocada en los detalles crÃ­ticos: la posiciÃ³n, la fuerza, la secuencia.

Nuestra responsabilidad no es solo usar bien la IA. Es educar activamente a las familias sobre sus limitaciones en emergencias. Y seguir insistiendo en el mensaje que no cambia: ante una emergencia, llama al ciento doce. La IA no salva vidas; el ciento doce sÃ­.` },

            {
                num: "24", name: "aepap_24.webm", text: `El meta-anÃ¡lisis en red mÃ¡s amplio publicado en JMIR reÃºne 168 estudios y casi treinta y seis mil preguntas clÃ­nicas. La pregunta clave: Â¿quÃ© modelo es mejor para quÃ©?

La respuesta, y esto es importante, es que ninguno gana en todo. ChatGPT-4o lidera en preguntas objetivas. ChatGPT-4 en preguntas abiertas. Gemini en triaje y clasificaciÃ³n.

Pero en diagnÃ³stico top-1, donde hay que acertar a la primera como hacemos cada dÃ­a en consulta, los humanos expertos siguen siendo superiores. Con un SUCRA de cero con noventa frente a cero con ochenta y uno de GPT-4. Traducido a lenguaje clÃ­nico: si tuviÃ©ramos que apostar quiÃ©n acierta el diagnÃ³stico mÃ¡s veces, el experto humano gana nueve de cada diez veces.

La implicaciÃ³n prÃ¡ctica es clara: no hay un modelo universal. Si necesitÃ¡is buscar evidencia, uno. Si necesitÃ¡is redactar, otro. Si necesitÃ¡is clasificar, otro. Y para lo mÃ¡s crÃ­tico, la primera sospecha diagnÃ³stica, vuestro criterio sigue siendo insustituible.` },

            {
                num: "25", name: "aepap_25.webm", text: `Â¿Y si usamos RAG para evaluar sesgo? Es una pregunta lÃ³gica: si el modelo trabaja con fuentes verificadas, Â¿no deberÃ­a evaluar mejor la calidad de un estudio?

Los datos dicen que no. Cuando se probÃ³ NotebookLM para evaluar riesgo de sesgo en estudios clÃ­nicos, la concordancia con revisores humanos fue muy baja: un coeficiente de correlaciÃ³n intraclase de cero con veintisiete. Traducido: de cada cuatro evaluaciones, la IA coincide con el experto apenas una vez, y las otras tres discrepa.

Â¿Por quÃ©? Porque evaluar sesgo requiere un tipo de juicio que va mÃ¡s allÃ¡ de procesar texto. Hay que inferir lo que el artÃ­culo no dice: Â¿por quÃ© no reportan el seguimiento? Â¿por quÃ© el grupo control es mÃ¡s joven? Eso es experiencia clÃ­nica y metodolÃ³gica, no procesamiento lingÃ¼Ã­stico.

Esto enlaza directamente con el semÃ¡foro que veremos en dos slides: evaluar calidad de evidencia es zona roja, por mucho que la herramienta tenga RAG.` },

            {
                num: "26", name: "aepap_26.webm", text: `Ahora un zoom a lo que mÃ¡s nos interesa: el diagnÃ³stico pediÃ¡trico.

En entornos rurales, donde el acceso a especialistas es limitado, la IA iguala prÃ¡cticamente al pediatra: 87.3% frente a 91.3%, una diferencia estadÃ­sticamente no significativa. Esto es relevante: imaginad un centro de salud rural en Extremadura con un mÃ©dico general solo, sin pediatra. AhÃ­ la IA como segunda opiniÃ³n puede ser transformadora.

Pero cuidado con extrapolar. A nivel global, como ya vimos, la IA es equivalente solo al mÃ©dico no especialista. El especialista sigue siendo netamente superior.

En salud mental, hay una progresiÃ³n real: el paso de GPT-3.5 a GPT-4 mejorÃ³ el F1 de 0.41 a 0.655. Traducido: pasÃ³ de acertar cuatro de cada diez a acertar seis o siete. Â¿Aceptable para detectar depresiÃ³n adolescente? Como cribado para derivar, posiblemente. Como diagnÃ³stico, ni de lejos.

Fijaos en el patrÃ³n que se repite: cuanto mÃ¡s estructurada y protocolizada la tarea, mejor rinde la IA. Cuanto mÃ¡s juicio clÃ­nico requiere, mÃ¡s lejos queda.` },

            {
                num: "27", name: "aepap_27.webm", text: `Tres lecciones del mismo campo, la escoliosis del adolescente, que ilustran por quÃ© no debemos confundir velocidad con fiabilidad, ni fiabilidad con consistencia.

Velocidad: la IA clasificÃ³ radiografÃ­as cien veces mÃ¡s rÃ¡pido, siete a cuarenta y ocho segundos frente a once o doce minutos. Impresionante. Pero cuando se repitiÃ³ la prueba una semana despuÃ©s, todos los modelos fallaron en reproducir sus propios resultados.

Fiabilidad: en guÃ­as protocolizadas de otorrinolaringologÃ­a, kappa igual a uno, cien por cien de adherencia. Perfecto. Pero el mismo tipo de modelo fabrica hasta el noventa y uno con cuatro por ciento de sus citas bibliogrÃ¡ficas.

Consenso: los cirujanos expertos coinciden el noventa y dos por ciento de las veces, con kappa de cero con novecientos trece. Los modelos de lenguaje multimodales: entre uno con seis y diez con dos por ciento, prÃ¡cticamente aleatorio.

La conclusiÃ³n: rÃ¡pido no es fiable. Fiable no es consistente. Tres dimensiones que no van juntas.` },

            {
                num: "29", name: "aepap_29.webm", text: `Los sesgos algorÃ­tmicos son un riesgo que debemos entender como clÃ­nicos, no solo como usuarios.

Aparecen en tres niveles, y cada uno tiene una consecuencia clÃ­nica distinta. En la entrada: los datos de entrenamiento pueden no representar a nuestra poblaciÃ³n. Un modelo entrenado mayoritariamente con datos de niÃ±os anglosajones puede infradiagnosticar dermatitis en piel oscura o malinterpretar patrones culturales de presentaciÃ³n del dolor.

En el proceso: la selecciÃ³n automatizada amplifica patrones preexistentes. Si los datos histÃ³ricos muestran menos derivaciones de TDAH en niÃ±as, el modelo aprenderÃ¡ que el TDAH es "cosa de niÃ±os" y perpetuarÃ¡ el infradiagnÃ³stico.

Y en la salida: las alucinaciones se presentan con alta confianza, sin seÃ±ales de alerta. No hay un indicador luminoso que diga "esto me lo estoy inventando."

La validaciÃ³n en poblaciones infrarrepresentadas no es un ideal; es una necesidad clÃ­nica. Lo que funciona en un hospital universitario de Boston no necesariamente aplica en un centro de salud de AlcorcÃ³n.` },

            {
                num: "30", name: "aepap_30.webm", text: `Os presento un semÃ¡foro de seguridad basado en toda la evidencia que hemos revisado. Y quiero que entendÃ¡is no solo los colores, sino por quÃ© cada tarea estÃ¡ donde estÃ¡.

Luz verde: automatizar con supervisiÃ³n tareas como revisiones sistemÃ¡ticas, extracciÃ³n de datos tabulares y generaciÃ³n de resÃºmenes estructurados. Â¿Por quÃ© verde? Porque son tareas donde el error es detectable y reversible. Si el modelo extrae mal un dato de una tabla, lo ves al revisar.

Luz amarilla: borradores de informes, sÃ­ntesis de historiales y apoyo al diagnÃ³stico diferencial. Â¿Por quÃ© amarillo? Porque el error puede pasar desapercibido si no cuestionas activamente. Recordad la paradoja de Wang: supervisar no es lo mismo que cuestionar.

Luz roja: diagnÃ³stico primario de imagen, planificaciÃ³n quirÃºrgica, dosificaciÃ³n sin verificaciÃ³n. Â¿Por quÃ© rojo? Porque el error tiene consecuencias irreversibles para el paciente y no siempre es detectable a tiempo.

Fijaos en que el criterio no es "la IA lo hace bien o mal." El criterio es: si se equivoca, Â¿puedo detectarlo antes de que cause daÃ±o? Esa es la pregunta que determina el color.` },


            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 2B Â· MARCO LEGAL (10 min)
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "32", name: "aepap_32.webm", text: `Bloque dos B: Marco Legal.

Antes de poner en prÃ¡ctica lo que sabemos, necesitamos conocer las reglas del juego. Porque usar inteligencia artificial con datos de pacientes no es solo una cuestiÃ³n tÃ©cnica. Es una cuestiÃ³n legal y Ã©tica que nos afecta directamente.` },

            {
                num: "33", name: "aepap_33.webm", text: `El marco legal que regula el uso de IA en consulta se apoya en tres pilares.

Primero, el Reglamento Europeo de Inteligencia Artificial, que clasifica las herramientas de IA por nivel de riesgo. Las herramientas diagnÃ³sticas certificadas se consideran de alto riesgo.

Segundo, el Reglamento General de ProtecciÃ³n de Datos, el RGPD, que regula el tratamiento de datos personales con especial protecciÃ³n para datos de salud.

Y tercero, la Ley 41/2002 de AutonomÃ­a del Paciente, que establece las bases del consentimiento informado.

Es importante distinguir: ChatGPT, Claude o Gemini no son productos sanitarios certificados. Para ellos, la norma vinculante hoy es el RGPD. Y en datos de salud pediÃ¡trica, las exigencias son mÃ¡ximas.` },

            {
                num: "34", name: "aepap_34.webm", text: `Hay un punto que debe quedar absolutamente claro: la responsabilidad clÃ­nica siempre es del mÃ©dico.

Da igual que la IA haya generado el borrador, sugerido el diagnÃ³stico o propuesto la dosis. La decisiÃ³n final, la firma, la responsabilidad legal y Ã©tica, es del profesional que actÃºa.

Esto es lo que llamamos el principio del "mÃ©dico en el bucle". La IA puede asistir, pero el acto mÃ©dico sigue siendo humano. Usar IA es legal y puede llegar a ser exigible por competencia profesional. Pero la responsabilidad clÃ­nica nunca se delega a un algoritmo.` },

            {
                num: "35", name: "aepap_35.webm", text: `Â¿QuÃ© datos puedes introducir en un modelo de IA? Depende del nivel de sensibilidad.

Nivel bajo, en verde: preguntas genÃ©ricas sobre guÃ­as o protocolos. Sin datos de paciente. Cualquier herramienta vale.

Nivel medio, en azul: consultas con datos anonimizados. AquÃ­ necesitas activar el modo efÃ­mero o temporal, para que la herramienta no almacene ni entrene con tu consulta.

Nivel alto, en naranja: imÃ¡genes o analÃ­ticas. Solo herramientas institucionales integradas en la historia clÃ­nica electrÃ³nica. Y es obligatoria una EvaluaciÃ³n de Impacto en ProtecciÃ³n de Datos.

Y nivel muy alto, en rojo: enfermedades raras. AquÃ­ se produce una situaciÃ³n especial: el setenta y cinco por ciento de pacientes con enfermedades raras tienen alto riesgo de reidentificaciÃ³n. En prevalencias menores de uno entre cincuenta mil, el nombre de la enfermedad mÃ¡s el paÃ­s puede bastar para identificar al paciente. Solo IA local o certificada, y reformular la consulta a nivel fisiopatolÃ³gico, sin nombrar la enfermedad.

Recordad el protocolo de treinta segundos: sustituir nombres por "paciente", edad exacta por rango, fechas por "hace tres dÃ­as", sin geografÃ­a, y nunca incluir nÃºmero de historia clÃ­nica ni DNI.` },

            {
                num: "36", name: "aepap_36.webm", text: `No todas las IAs son iguales en protecciÃ³n de datos. Os presento un semÃ¡foro de jurisdicciones.

Verde: despliegue local con modelos open-source como Llama o Mistral vÃ­a Ollama. Cero transferencia de datos, mÃ¡ximo control.

Azul: proveedores europeos como Mistral Le Chat o Azure EU. JurisdicciÃ³n de la UniÃ³n Europea, sin transferencia a terceros paÃ­ses.

Amarillo: proveedores americanos como OpenAI, Anthropic o Google, con Data Privacy Framework. Este acuerdo de adecuaciÃ³n entre la UE y Estados Unidos es vÃ¡lido pero frÃ¡gil, porque estÃ¡ recurrido ante el Tribunal de Justicia de la UniÃ³n Europea.

Y rojo: proveedores chinos como DeepSeek. Esencialmente incompatibles con el RGPD para datos de salud. Italia los prohibiÃ³ de emergencia en enero de dos mil veinticinco y la OCU ha denunciado ante la Agencia EspaÃ±ola de ProtecciÃ³n de Datos.

El mensaje clave: usar IA es legal y puede ser exigible, pero la responsabilidad clÃ­nica siempre es tuya. Anonimiza, documenta, y mantÃ©n el juicio crÃ­tico.` },

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 2C Â· APLICACIONES PRÃCTICAS (15 min)
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "37", name: "aepap_37.webm", text: `Bloque dos C: Aplicaciones PrÃ¡cticas.

Hemos visto los fundamentos, la evidencia y el marco legal. Ahora vamos a lo concreto: Â¿cÃ³mo puedes usar la IA en tu consulta de forma segura y efectiva?` },

            {
                num: "38", name: "aepap_38.webm", text: `Empiezo con la aplicaciÃ³n que tiene la evidencia mÃ¡s sÃ³lida, y probablemente la que mÃ¡s os importa a nivel personal: la reducciÃ³n de carga documental.

Un meta-anÃ¡lisis de catorce estudios confirma que la IA reduce moderada a altamente la carga de documentaciÃ³n clÃ­nica, con un tamaÃ±o de efecto de menos cero con setenta y uno, manteniendo la calidad comparable a la documentaciÃ³n manual.

Pensad en vuestro dÃ­a a dÃ­a: treinta y cinco pacientes citados, mÃ¡s las demandas, mÃ¡s las recetas, mÃ¡s los informes de derivaciÃ³n. Â¿CuÃ¡nto tiempo dedicÃ¡is a escribir y cuÃ¡nto a explorar al niÃ±o y hablar con la familia? La evidencia dice que la IA puede invertir esa proporciÃ³n.

Y hay un beneficio que rara vez se mide pero todos sentimos: la reducciÃ³n del burnout administrativo. No es que trabajemos menos; es que el trabajo que hacemos se parece mÃ¡s a la medicina que elegimos estudiar.

Esto conecta directamente con la inteligencia ambiental que veremos a continuaciÃ³n.` },

            {
                num: "39", name: "aepap_39.webm", text: `La inteligencia ambiental va un paso mÃ¡s allÃ¡. Imagina una herramienta que escucha la conversaciÃ³n en consulta, filtra lo clÃ­nicamente relevante y genera una nota estructurada automÃ¡ticamente.

Esto ya existe. El flujo es: escucha activa, filtrado inteligente de sÃ­ntomas y signos, y generaciÃ³n de documentaciÃ³n en formato SOAP o similar.

Pero hay un requisito Ã©tico que es innegociable: el consentimiento explÃ­cito del paciente o la familia antes de activar cualquier sistema de grabaciÃ³n. Sin consentimiento, no hay inteligencia ambiental que valga.` },

            {
                num: "40", name: "aepap_40.webm", text: `Llegamos a una idea que quiero que os llevÃ©is grabada: el prompt engineering ya es una habilidad clÃ­nica.

Callens y colaboradores proponen un checklist de cuatro pasos para interactuar con un modelo de IA de forma efectiva. Primero, definir el rol y el contexto. Segundo, especificar el output deseado. Tercero, incluir restricciones y limitaciones. Y cuarto, definir el formato de respuesta.

Â¿Os suena? Es la base del mÃ©todo RECORD que os enseÃ±arÃ© en el bloque de demos. Saber preguntar a la IA es tan importante como saber preguntar a un paciente.` },

            {
                num: "41", name: "aepap_41.webm", text: `Las cuatro tÃ©cnicas de prompting con mayor impacto segÃºn la evidencia son las siguientes.

Chain-of-Thought, o cadena de pensamiento: pedir al modelo que "piense paso a paso" mejora el rendimiento del diecisiete al cincuenta y ocho por ciento en tareas de razonamiento.

Few-shot: dar dos o tres ejemplos antes de la consulta. El formato importa mÃ¡s que las etiquetas.

RAG, o generaciÃ³n aumentada por recuperaciÃ³n: conectar el modelo a fuentes verificadas para reducir alucinaciones, con reducciones del dieciocho al cuarenta por ciento.

Y Self-Consistency: generar varias respuestas y elegir la mÃ¡s frecuente, con una mejora de casi dieciocho puntos porcentuales.

Pero atenciÃ³n: un estudio de Sclar y colaboradores demostrÃ³ que cambios triviales en el formato del prompt, como espaciado o puntuaciÃ³n, pueden causar variaciones de hasta setenta y seis puntos porcentuales en la precisiÃ³n. El cÃ³mo preguntas importa enormemente.` },

            {
                num: "42", name: "aepap_42.webm", text: `Dos mil veinticinco marca un cambio de paradigma. Los modelos de razonamiento como o1 o DeepSeek R1 internalizan el Chain-of-Thought. AsÃ­ que pedirles "piensa paso a paso" es redundante o incluso perjudicial.

El nuevo enfoque se llama Context Engineering: ya no se trata de encontrar las palabras perfectas, sino de dar la informaciÃ³n correcta en el momento adecuado. Herramientas mÃ¡s memoria mÃ¡s fuentes verificadas.

Para el pediatra de AtenciÃ³n Primaria, la clave es sencilla: con modelos clÃ¡sicos, usad el mÃ©todo RECORD con cadena de pensamiento. Con modelos de razonamiento, sed directos y dad contexto rico. Y siempre, siempre: fuentes verificadas mÃ¡s verificaciÃ³n del output.` },

            {
                num: "43", name: "aepap_43.webm", text: `Â¿DÃ³nde se concentra la evidencia actual? Esto es importante para calibrar expectativas.

El noventa y tres con cincuenta y cinco por ciento de los estudios evalÃºan modelos generalistas: GPT-4, Claude, Gemini. Los que vosotros ya podÃ©is usar. Solo el seis con cuarenta y cinco por ciento evalÃºa modelos mÃ©dicos especializados.

Â¿QuÃ© significa esto en la prÃ¡ctica? Que cuando leÃ©is un titular que dice "la IA diagnostica mejor que los mÃ©dicos", casi seguro estÃ¡n usando GPT-4 en un examen teÃ³rico. No un modelo mÃ©dico en vuestra consulta con un niÃ±o real.

Y la mÃ©trica mÃ¡s usada sigue siendo la precisiÃ³n simple: Â¿acierta o no acierta? Pero en clÃ­nica lo que nos importa es otra cosa: Â¿acierta cuando importa? Â¿Falla de forma peligrosa? Â¿Es consistente? Esas preguntas apenas se estÃ¡n empezando a responder.

La buena noticia: las herramientas que usarÃ©is hoy son exactamente las que la evidencia ha evaluado. La mala: queda mucho por hacer en evaluar modelos especÃ­ficos para pediatrÃ­a.` },

            {
                num: "44", name: "aepap_44.webm", text: `El ecosistema de IA mÃ©dica se diversifica en tres direcciones, y cada una tiene implicaciones distintas para vuestra prÃ¡ctica.

Los modelos open-source como DeepSeek ya igualan en rendimiento a los modelos propietarios, y permiten despliegue local. SÃ© lo que algunos estÃ¡is pensando: "yo no voy a instalar nada en mi ordenador." Pero la realidad es que no hace falta: los servicios de informÃ¡tica de las comunidades autÃ³nomas podrÃ­an desplegar estos modelos en servidores institucionales, con control total de los datos. Eso elimina el problema de la jurisdicciÃ³n que vimos en el bloque legal.

Los modelos mÃ©dicos especializados, como MedFound con ciento setenta y seis mil millones de parÃ¡metros, superan a los generalistas en diagnÃ³stico complejo en hasta ocho especialidades. Pero son menos accesibles y menos versÃ¡tiles.

Y la tercera direcciÃ³n es la IA agÃ©ntica: modelos que planifican y ejecutan tareas autÃ³nomamente. Un agente puede recibir "busca los Ãºltimos metaanÃ¡lisis sobre bronquiolitis, selecciona los tres mÃ¡s relevantes y genera un resumen para mi sesiÃ³n clÃ­nica", y ejecutar todo el flujo. Ya hay sistemas multi-agente con resultados prometedores.

Â¿La clave? No necesitÃ¡is elegir uno. NecesitÃ¡is saber cuÃ¡ndo usar cada uno: privacidad, precisiÃ³n o automatizaciÃ³n. Esas tres palabras definen la elecciÃ³n.` },

            {
                num: "45", name: "aepap_45.webm", text: `La inteligencia ambiental para documentaciÃ³n tiene el respaldo de un meta-anÃ¡lisis de veintitrÃ©s estudios. Y los resultados son consistentes: reducciÃ³n significativa de la fatiga administrativa.

Mirad esta infografÃ­a: el antes y el despuÃ©s. A la izquierda, lo que conocemos: la montaÃ±a de formularios, informes, hojas de derivaciÃ³n, notas en papel que luego hay que pasar. A la derecha, lo que ya existe: un resumen estructurado que el clÃ­nico revisa y valida en minutos.

Pero quiero ser honesto: esta tecnologÃ­a aÃºn tiene barreras reales en nuestro contexto. Requiere integraciÃ³n con la historia clÃ­nica electrÃ³nica, necesita consentimiento informado del paciente en cada consulta, y los sistemas en espaÃ±ol estÃ¡n menos desarrollados que los anglosajones.

Dicho esto, es la aplicaciÃ³n con el camino mÃ¡s claro hacia nuestra consulta. Y conecta con lo que vimos antes sobre el burnout: si la IA nos devuelve tiempo para el paciente, la ganancia no es solo administrativa, es clÃ­nica y emocional.` },

            {
                num: "46", name: "aepap_46.webm", text: `Los sistemas multi-agente son uno de los avances mÃ¡s interesantes de los Ãºltimos meses. En vez de un solo modelo respondiendo a todo, son varios modelos especializados trabajando coordinados: uno analiza la historia, otro cruza con bases de datos de sÃ­ntomas, otro revisa las guÃ­as clÃ­nicas, y un cuarto sintetiza.

Los nÃºmeros son prometedores: sensibilidad de cero con noventa y cuatro y exactitud de cero con ochenta y seis en cohortes de validaciÃ³n.

Â¿QuÃ© significa esto para vosotros? Imaginad un niÃ±o de seis aÃ±os con sÃ­ntomas inespecÃ­ficos: febrÃ­cula intermitente, cansancio, pÃ©rdida de apetito. Antes de derivar, un sistema multi-agente podrÃ­a cruzar esos sÃ­ntomas con marcadores analÃ­ticos y sugeriros un panel de estudio orientado. No sustituye vuestra sospecha clÃ­nica, pero la complementa con un procesamiento que a veces se nos escapa por saturaciÃ³n de la agenda.

Esto estÃ¡ en fase temprana, pero apuntadlo porque llegarÃ¡ a nuestras herramientas antes de lo que pensamos.` },

            {
                num: "47", name: "aepap_47.webm", text: `En pediatrÃ­a especÃ­ficamente, hay tres Ã¡reas donde la evidencia cuantitativa ya es sÃ³lida, y las tres comparten un rasgo: son tareas de cribado, no de diagnÃ³stico definitivo.

En neonatal: modelos especializados predicen morbilidad con suficiente antelaciÃ³n para ajustar el manejo. En retina: la detecciÃ³n de retinopatÃ­a del prematuro alcanza un F1 del ochenta y nueve por ciento. Traducido: de cada diez casos de ROP, detecta nueve. El dÃ©cimo se escapa, y por eso el oftalmÃ³logo sigue siendo imprescindible. Y en perioperatorio: la predicciÃ³n de hipoxemia tiene un AUC de cero con ochenta y cinco, suficiente para alertar al anestesista, no para actuar automÃ¡ticamente.

El patrÃ³n es claro: la IA destaca como sistema de alerta temprana. Detecta patrones que nosotros podemos pasar por alto cuando estamos saturados. Pero la decisiÃ³n clÃ­nica posterior sigue siendo nuestra. Y las dos siguientes slides muestran aplicaciones igual de concretas para atenciÃ³n primaria.` },

            {
                num: "48", name: "aepap_48.webm", text: `Un ejemplo que toca directamente la pediatrÃ­a de primaria: detecciÃ³n de caries en escolares mediante fotografÃ­as intraorales analizadas por IA.

Sensibilidad entre ochenta y dos y noventa y seis por ciento. Especificidad entre setenta y siete y noventa y nueve por ciento. Â¿QuÃ© significa esto en la prÃ¡ctica? Imaginad un programa de salud bucodental escolar: el enfermero escolar hace fotos con un protocolo estandarizado, la IA analiza las imÃ¡genes, y os llega una lista priorizada de quÃ© niÃ±os necesitan revisiÃ³n odontolÃ³gica urgente.

No sustituye al odontÃ³logo, pero optimiza la derivaciÃ³n en un sistema donde las listas de espera de dental son de meses. Y fijaos: otra vez el mismo patrÃ³n. La IA no diagnostica; criba. No decide; prioriza. Es el uso donde la evidencia es mÃ¡s consistente.` },

            {
                num: "49", name: "aepap_49.webm", text: `Un tema delicado pero que debemos abordar: la detecciÃ³n de riesgo suicida en adolescentes.

Los nÃºmeros son llamativos: la IA alcanza un noventa y nueve por ciento de detecciÃ³n en mensajes individuales. Pero esa cifra es engaÃ±osa. Detectar que un mensaje contiene palabras asociadas al suicidio es relativamente fÃ¡cil. Lo difÃ­cil, y lo clÃ­nicamente importante, es determinar si hay riesgo genuino. Y ahÃ­ el rendimiento cae al ochenta y nueve por ciento. Se recupera al noventa y uno cuando se aÃ±ade contexto conversacional completo.

Â¿QuÃ© implica esto para nosotros? Dos cosas. Primera: estas herramientas pueden ser un sistema de alerta en entornos digitales donde los adolescentes se expresan con mÃ¡s libertad que en consulta. Segunda: nunca, bajo ningÃºn concepto, pueden sustituir la entrevista clÃ­nica. Un mensaje que dice "no quiero vivir" puede ser una expresiÃ³n de frustraciÃ³n adolescente o un grito de auxilio real. Esa distinciÃ³n requiere empatÃ­a, contexto y juicio clÃ­nico, exactamente lo que la IA no tiene.` },

            {
                num: "50", name: "aepap_50.webm", text: `En formaciÃ³n mÃ©dica, los modelos de lenguaje son brillantes generando preguntas tipo test. Hasta el noventa y cuatro con cinco por ciento de precisiÃ³n en preguntas de elecciÃ³n mÃºltiple.

Pero recordad la brecha que vimos antes entre exÃ¡menes y clÃ­nica. Lo mismo aplica aquÃ­: un modelo que genera un caso clÃ­nico perfecto para un examen puede no capturar la ambigÃ¼edad real de una consulta. La variabilidad entre modelos es enorme cuando se les pone ante un caso clÃ­nico no estructurado.

Para vosotros, como tutores de residentes o formadores, la lecciÃ³n es esta: usad la IA para generar material docente, bancos de preguntas, casos simulados. Pero evaluad el razonamiento clÃ­nico con casos reales, no con preguntas tipo test. Esto aplica tanto a vuestros residentes como a la propia IA.` },

            {
                num: "51", name: "aepap_51.webm", text: `Un hallazgo que va a cambiar cÃ³mo usÃ¡is la IA a partir de hoy: el prompting determinista.

Con prompts estÃ¡ndar, preguntas abiertas del tipo "Â¿quÃ© diagnÃ³sticos consideras?", la adherencia a protocolos clÃ­nicos fue del treinta y dos por ciento. Noventa y seis de trescientos casos. Es decir, dos de cada tres veces el modelo se saliÃ³ del protocolo.

Con prompts deterministas, instrucciones cerradas, paso a paso, tipo checklist, "evalÃºa primero fiebre, luego signos menÃ­ngeos, luego focalidad", la adherencia subiÃ³ al cien por cien. Trescientos de trescientos.

Â¿Por quÃ©? Porque cuando le das libertad al modelo, "alucina creativamente." Cuando le das estructura, sigue el camino. Es exactamente lo que pasa con un residente: las instrucciones vagas producen resultados impredecibles; las instrucciones precisas producen resultados reproducibles.

Esto es la base del mÃ©todo RECORD que vais a aprender en las demos. No es un capricho de ingenierÃ­a; es la diferencia entre el treinta y dos y el cien por cien.` },

            {
                num: "52", name: "aepap_52.webm", text: `Esta matriz resume todo lo que hemos visto en una sola imagen. Cinco dominios clÃ­nicos, cada uno con su nivel de evidencia y seguridad.

AdministraciÃ³n y educaciÃ³n: verde, nivel alto. Es donde la evidencia es mÃ¡s consistente y el riesgo de daÃ±o mÃ¡s bajo. DiagnÃ³stico e investigaciÃ³n: amarillo, nivel medio. Funciona, pero necesita supervisiÃ³n activa y metodolÃ³gica. Salud mental: rojo, nivel bajo. Los avances son prometedores, pero la evidencia es preliminar y el riesgo Ã©tico es alto.

Â¿Por quÃ© importa esta matriz? Porque os da un criterio para cuando un compaÃ±ero os diga "he visto que la IA diagnostica autismo." PodÃ©is mirar la matriz y decir: "sÃ­, pero estamos en amarillo tirando a rojo; necesitamos validaciÃ³n clÃ­nica antes de confiar."

Es la chuleta del seminario. EstÃ¡ en los materiales y os la podÃ©is llevar impresa.` },

            {
                num: "53", name: "aepap_53.webm", text: `La generaciÃ³n aumentada por recuperaciÃ³n, RAG, se consolida como el estÃ¡ndar de implementaciÃ³n segura. Y quiero que entendÃ¡is por quÃ©, no solo que lo aceptÃ©is.

Un modelo de lenguaje sin RAG responde desde su memoria de entrenamiento, que puede estar desactualizada, incompleta o directamente equivocada. Un modelo con RAG busca primero en fuentes que vosotros o el sistema habÃ©is seleccionado, y responde solo desde lo encontrado. Es la diferencia entre un mÃ©dico que receta de memoria y uno que consulta el PediamÃ©cum antes de firmar.

Herramientas como Open Evidence trabajan con fuentes biomÃ©dicas curadas. Perplexity Pro busca en web acadÃ©mica con citas en tiempo real. Y NotebookLM os permite chatear con vuestros propios PDFs: protocolos de centro, guÃ­as AEPAP, artÃ­culos que habÃ©is seleccionado.

La regla prÃ¡ctica: para cualquier consulta clÃ­nica point-of-care, usad siempre herramientas con RAG. Para redacciÃ³n y formato, el modelo base es suficiente. Esa distinciÃ³n es la que separa el uso seguro del inseguro.` },

            {
                num: "54", name: "aepap_54.webm", text: `Un estudio de Masanneck y colaboradores demuestra algo con implicaciones prÃ¡cticas inmediatas.

Restringir las fuentes del modelo a fuentes profesionales mejora la precisiÃ³n del sesenta al setenta y ocho por ciento. Dieciocho puntos porcentuales de mejora.

Y al revÃ©s: usar aunque sea una fuente no profesional reduce las odds de respuesta correcta a la mitad.

La acciÃ³n es directa: configurad vuestros modelos para trabajar con guÃ­as AEPAP, protocolos de AEPED, PediamÃ©cum y guÃ­as internacionales pediÃ¡tricas. Limitad las fuentes y multiplicarÃ©is la fiabilidad.` },

            {
                num: "55", name: "aepap_55.webm", text: `Cuatro conclusiones que sintetizan toda la evidencia que hemos revisado, y quiero que notÃ©is cÃ³mo cada una conecta con lo que hemos visto.

Primera: la IA aumenta al mÃ©dico, no lo sustituye. Es el modelo Human-in-the-Loop del que hablamos al principio. Segunda: la reducciÃ³n de burocracia es real y significativa, pero en diagnÃ³stico la supervisiÃ³n es obligatoria. Es la diferencia entre zona verde y zona roja del semÃ¡foro. Tercera: los modelos especializados superan a los generalistas, pero aÃºn son minorÃ­a en la evidencia. Y cuarta: verificaciÃ³n antes de uso clÃ­nico. Siempre. Porque el 26 a 36 por ciento de errores persiste incluso con supervisiÃ³n humana.

Estas cuatro ideas las vais a ver en acciÃ³n ahora mismo. Porque una cosa es entender la teorÃ­a y otra muy distinta es ver cÃ³mo funciona cuando te sientas delante de la pantalla.` },

            {
                num: "56", name: "aepap_56.webm", text: `Para terminar este bloque, la hoja de ruta traducida a vuestra consulta de atenciÃ³n primaria. Es diferente del semÃ¡foro general que vimos antes porque estÃ¡ pensada para las tareas que hacÃ©is todos los dÃ­as.

Verde: adoptad la IA para documentaciÃ³n, hojas informativas para familias y sÃ­ntesis de evidencia. Son las tareas que os roban tiempo sin aportar juicio clÃ­nico. Delegadlas con supervisiÃ³n.

Amarillo: apoyo al diagnÃ³stico diferencial con RAG, preparaciÃ³n de sesiones clÃ­nicas, codificaciÃ³n CIE. AquÃ­ la IA os ahorra tiempo, pero tenÃ©is que cuestionar activamente cada resultado. No basta con leerlo; hay que contrastarlo.

Rojo: diagnÃ³stico autÃ³nomo, dosificaciÃ³n sin verificaciÃ³n, cualquier uso donde no revisÃ¡is el output antes de que llegue al paciente o a la historia clÃ­nica.

Fijaos en la diferencia con el semÃ¡foro general: aquÃ­ el amarillo incluye RAG porque herramientas como Open Evidence o Perplexity Pro reducen significativamente el riesgo de alucinaciÃ³n. Pero no lo eliminan, y por eso sigue siendo amarillo, no verde.` },

            {
                num: "57", name: "aepap_57.webm", text: `Cinco mensajes clave antes de pasar a las demos. Y fijaos en cÃ³mo cada uno conecta con algo concreto que hemos visto.

Uno: la evidencia mÃ¡s sÃ³lida estÃ¡ en documentaciÃ³n y sÃ­ntesis. El meta-anÃ¡lisis de catorce estudios lo confirma. Semiautomatizad con revisiÃ³n humana.

Dos: en diagnÃ³stico pediÃ¡trico real, la IA como segunda opiniÃ³n, nunca como sustituto. Recordad la brecha entre el 84-90% en exÃ¡menes y el 52% en clÃ­nica real.

Tres: los modelos open-source on-premise ya son competitivos y resuelven el problema de jurisdicciÃ³n. DeepSeek local es una opciÃ³n real.

Cuatro: los modelos mÃ©dicos especializados rinden mejor en tareas diagnÃ³sticas, pero solo el 6% de los estudios los evalÃºa. Queda camino.

Y cinco: los prompts deterministas con checklists transforman la adherencia del treinta y dos al cien por cien. El mÃ©todo RECORD que vais a practicar estÃ¡ basado en este principio.

Estos cinco puntos son la base. Ahora vamos a ver cÃ³mo se traducen en herramientas que podÃ©is usar el lunes.` },

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 3 Â· DEMOS EN VIVO (40 min)
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "58", name: "aepap_58.webm", text: `Bloque tres: Demos en vivo.

Hasta ahora hemos hablado de evidencia y de conceptos. Ahora viene la parte que mÃ¡s me gusta: ver las herramientas funcionando en tiempo real.

Vamos a navegar el ecosistema de IA disponible, y vais a ver exactamente cÃ³mo se usa cada herramienta.` },

            {
                num: "59", name: "aepap_59.webm", text: `Para navegar este ecosistema necesitamos un mapa. Os presento la PirÃ¡mide de Evidencia 5.0, adaptada del modelo clÃ¡sico de Alper y Haynes.

En la cima estÃ¡n las herramientas point-of-care con RAG clÃ­nico: Open Evidence, Perplexity Pro, NotebookLM. Dan respuestas verificables con citas a fuentes de alta calidad. Son las mÃ¡s seguras.

En el nivel medio: herramientas de bÃºsqueda y sÃ­ntesis como Undermind, Scite.ai, Elicit o Consensus. Agentes de investigaciÃ³n que sintetizan literatura.

Y en la base: los modelos fundacionales como ChatGPT, Claude o Gemini. Razonan bien, pero su conocimiento estÃ¡ "congelado" y tienen riesgo de alucinaciÃ³n.

La regla es sencilla: para decisiones clÃ­nicas, subid lo mÃ¡s alto posible en la pirÃ¡mide. Para tareas de redacciÃ³n o formato, la base puede ser suficiente.` },

            {
                num: "60", name: "aepap_60.webm", text: `AquÃ­ tenÃ©is el catÃ¡logo completo, organizado por tipo, uso principal y nivel de confianza.

Open Evidence y Perplexity Pro: RAG clÃ­nico, confianza alta. NotebookLM: RAG personal sobre tus propios documentos, confianza alta. Scite.ai: anÃ¡lisis de citas, confianza moderada. Y ChatGPT o Claude: modelos fundacionales, confianza alta para redacciÃ³n y formato, pero baja para datos clÃ­nicos sin verificaciÃ³n externa.

Fijaos en el asterisco: la confianza de los modelos fundacionales cambia radicalmente segÃºn la tarea. Redactar un email a una familia: alto. Calcular una dosis: bajo.` },

            {
                num: "61", name: "aepap_61.webm", text: `Vamos a ver un caso de uso real que podÃ©is replicar maÃ±ana en vuestro centro de salud.

El flujo es este: empezamos con una bÃºsqueda avanzada en PubMed que filtra revisiones sistemÃ¡ticas y metaanÃ¡lisis del Ãºltimo mes, centrada en las diez patologÃ­as mÃ¡s frecuentes de nuestra consulta pediÃ¡trica: TDAH, TEA, bronquiolitis, asma, infecciones respiratorias de vÃ­as altas, otitis, gastroenteritis, dermatitis atÃ³pica, obesidad y ansiedad.

Cargamos los abstracts en NotebookLM. Y a partir de ahÃ­, la herramienta genera tres productos: un podcast tipo journal club de mÃ¡s de veinte minutos que puedes escuchar en el coche camino al trabajo, una presentaciÃ³n de diapositivas para tu sesiÃ³n clÃ­nica, y un vÃ­deo resumen.

Todo a partir de la misma fuente de evidencia verificable. La IA no inventa nada porque trabaja exclusivamente sobre los artÃ­culos que tÃº le has dado. Eso es RAG en acciÃ³n.

VeÃ¡moslo en directo.` },

            {
                num: "62", name: "aepap_62.webm", text: `Ahora vamos a ver el mÃ©todo RECORD, que es el framework que os propongo para escribir prompts efectivos.

RECORD es un acrÃ³nimo de seis letras.

R de Rol: dile al modelo quiÃ©n es. "ActÃºa como pediatra de AtenciÃ³n Primaria."

E de Escenario: sitÃºa la acciÃ³n. "En consulta de seguimiento."

C de Contexto: da los datos clÃ­nicos relevantes. "Lactante de tres meses con bronquiolitis."

O de Objetivo: di exactamente quÃ© quieres obtener. "Genera una hoja informativa para padres."

R de Restricciones: marca los lÃ­mites. "Sin tÃ©rminos mÃ©dicos, sin causar alarma."

Y D de DiseÃ±o: define el formato. "Cinco secciones con signos de alarma destacados."

Cuanto mÃ¡s completo sea tu prompt, mÃ¡s Ãºtil serÃ¡ la respuesta. Vamos a construir uno en vivo.` },

            {
                num: "63", name: "aepap_63.webm", text: `Una de las funcionalidades mÃ¡s potentes de estos modelos es la personalizaciÃ³n.

PodÃ©is crear mini-asistentes preconfigurados, los llaman GPTs en ChatGPT, Gems en Gemini, sin saber programar. Le das las instrucciones una vez, y a partir de ahÃ­ el modelo las aplica automÃ¡ticamente cada vez que lo usas.

Un ejemplo concreto: un GPT que reciba resultados analÃ­ticos anonimizados y genere una versiÃ³n explicativa para padres, mÃ¡s pistas de interpretaciÃ³n clÃ­nica y sugerencias para ampliar estudio.

Otros usos: generador de informes, traductor de jerga mÃ©dica, asistente de codificaciÃ³n CIE-10, preparador de sesiones clÃ­nicas.

La clave: una vez configurado, el asistente recuerda las instrucciones y aplica el mismo formato cada vez. Es como tener un residente digital que no se cansa y no se equivoca, siempre que le hayas dado bien las instrucciones.` },

            {
                num: "64", name: "aepap_64.webm", text: `AquÃ­ tenÃ©is el constructor de prompts interactivo, una herramienta de cÃ³digo abierto que he desarrollado para este seminario.

PodÃ©is interactuar directamente con ella. Seleccionad un escenario, rellenad los campos del mÃ©todo RECORD, y el constructor genera el prompt completo listo para copiar y pegar en cualquier modelo de IA.

Probadla. EstÃ¡ disponible en mi web y os la llevÃ¡is para usar en vuestra consulta.` },

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 4 Â· PRÃCTICA GUIADA (25 min)
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "65", name: "aepap_65.webm", text: `Bloque cuatro: PrÃ¡ctica Guiada.

Ahora os toca a vosotros. HabÃ©is visto la evidencia, habÃ©is visto las herramientas, habÃ©is visto el mÃ©todo. Es hora de ponerlo en prÃ¡ctica.` },

            {
                num: "66", name: "aepap_66.webm", text: `AquÃ­ tenÃ©is tres plantillas listas para usar, basadas en escenarios reales de pediatrÃ­a de primaria.

InformaciÃ³n para padres: genera una hoja explicativa sobre cualquier patologÃ­a. SesiÃ³n clÃ­nica: resume un artÃ­culo para presentar en cinco minutos. Email a familia: responde una consulta de forma empÃ¡tica y profesional.

Haced clic en cualquiera de ellas y obtendrÃ©is un prompt RECORD completo que podÃ©is copiar, adaptar y usar inmediatamente. Escanead tambiÃ©n el QR del kit de supervivencia para acceder a mÃ¡s plantillas.` },

            {
                num: "67", name: "aepap_67.webm", text: `Bien, ahora la prÃ¡ctica.

Formad parejas o trÃ­os. Elegid uno de estos tres casos.

Caso uno: generar informaciÃ³n para padres sobre varicela, con cuidados en casa y signos de alarma. Caso dos: resumir un artÃ­culo sobre bronquiolitis para una sesiÃ³n clÃ­nica de cinco minutos. Caso tres: responder por email a una madre que pregunta sobre introducciÃ³n de alimentaciÃ³n complementaria.

Usad el mÃ©todo RECORD. TenÃ©is quince minutos. PodÃ©is usar la plantilla impresa o la herramienta online con el QR.

Al terminar, compartiremos algunos ejemplos y veremos quÃ© funciona y quÃ© se puede mejorar.

Adelante.` },

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // BLOQUE 5 Â· CIERRE (20 min)
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            {
                num: "68", name: "aepap_68.webm", text: `Bloque cinco: Cierre.

Llegamos al final. Vamos a recapitular lo esencial y asegurarnos de que os llevÃ¡is las herramientas y los conceptos bien consolidados.` },

            {
                num: "69", name: "aepap_69.webm", text: `Si tuviera que resumir todo el seminario en una sola imagen, serÃ­a esta: el Modelo SÃ¡ndwich.

Tres capas.

Pan superior: el humano. TÃº defines la estrategia, eliges la herramienta, formulas la pregunta correcta. Sin una buena pregunta, no hay buena respuesta.

Relleno: la IA. Procesa datos masivamente, genera borradores, sintetiza evidencia, busca patrones. Hace el trabajo pesado que antes nos robaba horas.

Pan inferior: el humano de nuevo. Verificas los hechos, validas el contexto clÃ­nico, y tomas la decisiÃ³n final asumiendo la responsabilidad.

El relleno puede cambiar, hoy es GPT-4, maÃ±ana serÃ¡ otro modelo, pero el pan siempre es humano. La verificaciÃ³n al final no es opcional. Es innegociable.` },

            {
                num: "70", name: "aepap_70.webm", text: `Tres cosas que os llevÃ¡is para casa. Solo tres, porque si son mÃ¡s, no os acordarÃ©is de ninguna.

Primero: el Modelo SÃ¡ndwich. Humano define, IA procesa, humano verifica. La responsabilidad siempre es tuya.

Segundo: el MÃ©todo RECORD. Rol, Escenario, Contexto, Objetivo, Restricciones, DiseÃ±o. La calidad del output depende de la calidad del prompt.

Y tercero: el Detector de Alucinaciones. Verifica siempre las referencias y los datos especÃ­ficos. Usa herramientas con RAG como Open Evidence o Perplexity Pro.

Tres herramientas mentales. Tres escudos. LlevÃ¡oslos al centro de salud.` },

            {
                num: "71", name: "aepap_71.webm", text: `Primera pregunta de evaluaciÃ³n.

De las siguientes opciones, Â¿cuÃ¡l representa la aplicaciÃ³n mÃ¡s segura de IA generativa en la consulta de pediatrÃ­a de AtenciÃ³n Primaria?

Uno: sustituir la consulta con dermatologÃ­a. Dos: prescribir autÃ³nomamente. Tres: diagnosticar TDAH. Cuatro: interpretar una espirometrÃ­a sin validaciÃ³n. O cinco: generar un borrador de informaciÃ³n para padres sobre gastroenteritis.

La respuesta es la cinco. Bajo riesgo clÃ­nico, alto valor comunicativo, y siempre, siempre, con revisiÃ³n del pediatra antes de entregar.` },

            {
                num: "72", name: "aepap_72.webm", text: `Segunda pregunta.

SegÃºn la paradoja humano mÃ¡s IA que vimos, Â¿cuÃ¡l es el riesgo principal de aÃ±adir supervisiÃ³n humana a las respuestas de IA?

Uno: aumentar el coste. Dos: generar falsa confianza sin reducir errores. Tres: ralentizar el flujo. Cuatro: reducir la autonomÃ­a profesional. O cinco: crear dependencia tecnolÃ³gica.

La respuesta es la dos. Recordad: el meta-anÃ¡lisis de Wang mostrÃ³ que los errores persisten en un veintisÃ©is a treinta y seis por ciento incluso con supervisiÃ³n humana, porque la supervisiÃ³n puede generar una falsa sensaciÃ³n de seguridad.` },

            {
                num: "73", name: "aepap_73.webm", text: `Y con esto llegamos al final.

"Homines, dum docent, discunt." Los hombres, mientras enseÃ±an, aprenden.

Os aseguro que preparar este seminario me ha enseÃ±ado tanto como espero que os haya enseÃ±ado a vosotros. La inteligencia artificial es una herramienta extraordinaria, pero solo si la usamos con rigor, con humildad y con el paciente siempre en el centro.

Recordad el sÃ¡ndwich. Recordad RECORD. Y recordad verificar.

Muchas gracias por vuestra atenciÃ³n, vuestra participaciÃ³n y vuestra generosidad compartiendo experiencias. Los materiales y todas las herramientas estÃ¡n en mi web. Y como siempre, mi buzÃ³n estÃ¡ abierto para preguntas, sugerencias o para seguir aprendiendo juntos.

Gracias.` },
        ];

        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // Block titles for visual grouping
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        const blocks = [
            { before: 0, title: "BLOQUE 0 Â· Portada y Encuadre" },
            { before: 4, title: "BLOQUE 1 Â· Ruptura (15 min)" },
            { before: 9, title: "BLOQUE 2A Â· Fundamentos TeÃ³ricos (10 min)" },
            { before: 13, title: "Evidencia CientÃ­fica" },
            { before: 31, title: "BLOQUE 2B Â· Marco Legal (10 min)" },
            { before: 36, title: "BLOQUE 2C Â· Aplicaciones PrÃ¡cticas (15 min)" },
            { before: 57, title: "BLOQUE 3 Â· Demos en Vivo (40 min)" },
            { before: 64, title: "BLOQUE 4 Â· PrÃ¡ctica Guiada (25 min)" },
            { before: 67, title: "BLOQUE 5 Â· Cierre (20 min)" },
        ];

        const STORAGE_KEY = "aepap_audios_done_v2";
        const LEGACY_STORAGE_KEY = "aepap_audios_done";

        function migrateDoneIfNeeded() {
            try {
                const hasV2 = localStorage.getItem(STORAGE_KEY);
                if (hasV2 !== null) return;

                const legacyRaw = localStorage.getItem(LEGACY_STORAGE_KEY);
                if (!legacyRaw) return;

                const validNums = new Set(audios.map(a => a.num));
                const legacyDone = JSON.parse(legacyRaw);
                if (!Array.isArray(legacyDone)) return;

                const migrated = [];
                legacyDone.forEach(n => {
                    const parsed = Number(n);
                    if (!Number.isFinite(parsed)) return;

                    const shifted = String(parsed + 1);
                    if (!validNums.has(shifted)) return;
                    if (!migrated.includes(shifted)) migrated.push(shifted);
                });

                localStorage.setItem(STORAGE_KEY, JSON.stringify(migrated));
            } catch {
                // Ignore malformed legacy storage and continue with defaults.
            }
        }
        function getDone() {
            try { return JSON.parse(localStorage.getItem(STORAGE_KEY)) || []; }
            catch { return []; }
        }
        function saveDone(arr) { localStorage.setItem(STORAGE_KEY, JSON.stringify(arr)); }

        function updateProgress() {
            const done = getDone();
            const total = audios.length;
            const count = done.length;
            document.getElementById("progress-text").textContent = `${count} / ${total}`;
            document.getElementById("progress-fill").style.width = `${(count / total) * 100}%`;
        }

        function showToast(msg) {
            const t = document.getElementById("toast");
            t.textContent = msg;
            t.classList.add("show");
            setTimeout(() => t.classList.remove("show"), 1500);
        }

        function copyText(num) {
            const a = audios.find(x => x.num === num);
            if (!a) return;
            navigator.clipboard.writeText(a.text).then(() => showToast("âœ… Texto copiado"));
        }

        function markDone(num) {
            const done = getDone();
            if (!done.includes(num)) { done.push(num); saveDone(done); }
            const el = document.getElementById(`audio-${num}`);
            if (el) {
                el.classList.add("done");
                el.querySelector(".btn-done").style.display = "none";
                el.querySelector(".btn-undo").style.display = "inline-block";
            }
            updateProgress();
        }

        function undoDone(num) {
            let done = getDone();
            done = done.filter(x => x !== num);
            saveDone(done);
            const el = document.getElementById(`audio-${num}`);
            if (el) {
                el.classList.remove("done");
                el.querySelector(".btn-done").style.display = "inline-block";
                el.querySelector(".btn-undo").style.display = "none";
            }
            updateProgress();
        }

        function render() {
            const list = document.getElementById("audio-list");
            const done = getDone();
            const blockMap = {};
            blocks.forEach(b => { blockMap[b.before] = b.title; });

            let html = "";
            audios.forEach((a, i) => {
                if (blockMap[i] !== undefined) {
                    html += `<div class="block-title">ğŸ“¦ ${blockMap[i]}</div>`;
                }
                const isDone = done.includes(a.num);
                html += `<div class="audio-item ${isDone ? 'done' : ''}" id="audio-${a.num}">
            <div class="audio-header">
                <span class="audio-num">#${a.num}</span>
                <span class="audio-name">ğŸ“ ${a.name}</span>
            </div>
            <div class="audio-text">${a.text}</div>
            <div class="audio-actions">
                <button class="btn btn-copy" onclick="copyText('${a.num}')">ğŸ“‹ Copiar</button>
                <button class="btn btn-done" onclick="markDone('${a.num}')" style="${isDone ? 'display:none' : ''}">âœ… Hecho</button>
                <button class="btn btn-undo" onclick="undoDone('${a.num}')" style="${isDone ? '' : 'display:none'}">â†©ï¸ Deshacer</button>
            </div>
        </div>`;
            });
            list.innerHTML = html;
            updateProgress();
        }

        migrateDoneIfNeeded();
        render();
    </script>
</body>

</html>