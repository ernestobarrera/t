# Guiones de Audio Definitivos — AEPap 2026
# Última actualización: 2026-02-19
# Próxima slide pendiente: 2B.17 (Gaps Críticos, deck #30 → renumerar tras consolidación)
# Slides completadas: 0.1 a 2B.18 (31 slides, de las cuales 2B.18 consolida 3 originales)

## ACTUALIZACIONES 2026-02-19

- 2B.16 (deck #29): audio + HTML cerrados. Imagen IA_Potencia_09.jpg → tabla HTML semáforo 3 columnas. Refs con DOI hyperlinks: Lee Value Health 2025 · Asgari npj Digit Med 2025 · Takita npj Digit Med 2025 · Beber JPOSNA 2025 · Aktan Diagnostics 2025 · Bushuven J Med Syst 2023. Assertion: "detectabilidad del error". ~70s
- 2B.13 (deck #27): audio + HTML cerrados. Güneş reemplaza Bard en panel Fiabilidad. Durgut ORL 2026. Duda pendiente: ¿eliminar 2B.14 por duplicación?
- 2B.15 (deck #28): audio + HTML rediseñado. Imagen eliminada → 3 paneles HTML. Refs: Hasanzadeh npj Digit Med 2025 (50% alto RoB)

## ACTUALIZACIONES 2026-02-19 (sesión 2)

- 2B.18 (deck #30): CONSOLIDADA de 2B.18+19+20. 3 niveles riesgo + desidentificación 30" + jurisdicciones 3 líneas + checklist 6 ítems. Tooltips corregidos (title nativo vs abbr-tip). "Modo efímero" → "sin historial ni entrenamiento" + nombres por plataforma. "Anonimizar" → "desidentificar". Footer compactado a 2 líneas. Audio ~95s sigue secuencia visual. WMA PITL verificado. DPF status actualizado (validado sep 2025, apelado oct 2025).



## ESTADO POR SLIDE

| Slide | Deck# | Estado | Notas |
|-------|-------|--------|-------|
| 0.1 Portada | 1 | ✅ | — |
| 0.2 Conflicto de Intereses | 2 | ✅ | Tono neutro, sin "sesgo explícito" |
| 0.3 Objetivos | 3 | ✅ | No leer objetivos, encuadre crítico |
| 0.4 Hoja de Ruta | 4 | ✅ | Sin tiempos, lógica pedagógica |
| 1.0 Bloque 1: Ruptura | 5 | ✅ | Justifica "ruptura" como concepto |
| 1.1 Encuesta Inicial | 6 | ✅ | Adaptada offline, "tú" singular |
| 1.2 Pizarra/ChatGPT | 7 | ✅ | Datos verificados: 1M/5d, 100M/2m, 800M actual |
| 1.3 Bibliometría | 8 | ✅ | 1/215→1/90. Cierre epistemológico |
| 1.4 Dos historias | 9 | ✅ | Historia TEA en vez de GEA. Cierre "tecnología sanitaria" |
| 2A.0 Bloque 2A | 10 | ✅ | Art.4 AI Act, alfabetización obligatoria |
| 2A.1 Glosario | 11 | ✅ | 9 conceptos. Audio prioriza LLM, alucinación, RAG, modelo fundacional |
| 2A.2 Flujo Clínico | 12 | ✅ | Li JMIR 2025 (270 estudios). MedR-Bench contraste. Ref pie corregida |
| 2A.3 ¿Qué es un LLM? | 13 | ✅ | Analogía texto predictivo móvil. ~55s |
| 2B.0 Bloque 2B: Evidencia | 14 | ✅ | Sin spoiler Goh. "Ruido y miedo." ~15s |
| 2B.1 Human-in-the-Loop | 15 | ✅ | Goh Nat Med 2025: +6.5%, +119s. Coste-beneficio |
| 2B.2 Paradigma Colaboración | 16 | ✅ | Takita 52.1% + Wang +4.88pp. "Supervisar ≠ cuestionar" |
| 2B.3 Paradoja H+AI | 17 | ✅ | Wang RR 1.59 NS. Deskilling. ~55s |
| 2B.4 Sesgos Cognitivos | 18 | ✅ | Kahneman dual. 3 sesgos. Regla de oro. ~50s |
| 2B.4bis Pausa Interactiva | 19 | ✅ | Offline: reflexión interna. Slide mantiene "levantad la mano" |
| 2B.5 Precisión Diagnóstica | 20 | ✅ | Takita 83 estudios + Wang JMIR NMA. "No sabrás cuál mitad" |
| 2B.8 Alucinaciones | 21 | ✅ | Chelli (biblio) + Asgari (clínica). Omisiones > alucinaciones |
| 2B.8bis Brecha Exámenes vs Clínica | 22 | ✅ | Takita 52.1% real vs 84-90% examen. 9.4% evalúa daño. ~55s |
| 2B.9 Riesgo: Dr. AI | 23 | ✅ | Bushuven JMS 2023 + Kular Cureus 2025. Imagen eliminada, gráfico inline. "puede fallar" |
| 2B.9bis NMA JMIR | 24 | ✅ | Pendiente confirmar autoría: ¿Wang L o Gong et al.? |
| 2B.11 RAG y sesgo | 25 | ✅ | HTML: inglés→español, año→2026, nota RAG al pie. Audio: "observacionales" pendiente |
| 2B.12 Diagnóstico Pediátrico | 26 | ✅ | Rediseñada: 3 paneles→2 paneles. Mansoor rural + Del Monte urgencias + Sun psiquiatría edad. Título: "depende del contexto" |

| 2B.13 Rápido ≠ fiable ≠ consistente | 27 | ✅ | Aktan AIS + Durgut ORL + Güneş refs. Duda: ¿eliminar 2B.14 por duplicación? ~68s |
| 2B.15 Sesgos Algorítmicos | 28 | ✅ | HTML rediseñado sin imagen. 3 paneles (input/proceso/output). Hasanzadeh 2025. "Boston vs Alcorcón". ~65s |
| 2B.16 Semáforo IA | 29 | ✅ | Imagen IA_Potencia_09.jpg → tabla HTML 3 columnas. Assertion: "detectabilidad del error". DOI hyperlinks. ~70s |
| 2B.18 Marco Legal (consolidada) | 30 | ✅ | Fusión 2B.18+19+20. 3 niveles riesgo + desidentificación 30" + jurisdicciones + checklist. Tooltips con title nativo. ~95s |

## CONVENCIONES TTS

- Siglas en fonética española: "ene-pe-jota" (npj), "YAMA" (JAMA)
- Números siempre en letra: "cincuenta y dos por ciento", "ochenta y tres estudios"
- "jiuman in de lup" para human-in-the-loop
- Evitar paréntesis, guiones largos y construcciones que TTS lea mal
- Puntos y comas para pausas naturales
- El texto en data-audio-text del HTML va en UNA SOLA LÍNEA (sin \n) porque el TTS se para 

## TEXTOS DEFINITIVOS

---

### 0.1 — Portada

Bienvenidos al seminario "La Inteligencia Artificial como 
Asistente del Pediatra de Atención Primaria".

Soy médico de familia en la Comunidad de Madrid, y llevo 
años combinando la práctica clínica con la formación y las 
herramientas digitales.

Durante las próximas dos horas vamos a explorar juntos tres 
cuestiones que considero esenciales. Primera: dónde puede 
ayudarnos la IA hoy, con evidencias reales. Segunda: dónde 
puede hacernos daño si la usamos mal. Y tercera, y quizá la 
más práctica: cómo interactuar con ella para obtener 
resultados útiles y seguros en nuestra consulta.

Será un seminario con elementos prácticos. Vais a ver demos 
en vivo, vais a practicar vosotros mismos, y os vais a 
llevar herramientas que podéis usar el lunes en vuestra 
consulta.

Empecemos.

---

### 0.2 — Conflicto de Intereses

Antes de entrar en materia, la declaración obligada: no 
tengo conflictos de interés relacionados con este contenido. 
Las herramientas que mencionaré son de uso personal y no 
tengo vinculación comercial con ningún proveedor de 
inteligencia artificial.

Lo que sí quiero dejar claro desde el principio es el 
enfoque del seminario: vamos a tratar la IA con el mismo 
rigor con el que evaluamos cualquier otra intervención 
clínica. Evidencia, limitaciones y aplicación práctica.

---

### 0.3 — Objetivos del Seminario

Estos que veis en pantalla son los tres objetivos del 
seminario.

Quiero destacar el hilo que los conecta: no vamos a 
aprender a usar ChatGPT. Eso lo podéis hacer solos en casa 
en media hora. Lo que vamos a hacer es algo que requiere más 
tiempo y más matices: desarrollar criterio clínico para 
saber cuándo una herramienta de IA os aporta valor real, 
cuándo os está dando una respuesta que parece brillante pero 
es incorrecta, y cuándo directamente no deberíais estar 
usándola. Y además, aprenderemos algunos trucos para 
trabajar con los modelos de lenguaje que ya tenemos a 
nuestro alcance y que podéis usar el lunes en vuestra 
consulta.

Porque el riesgo de estas herramientas no es que sean 
difíciles de usar. Al contrario, son tremendamente fáciles. 
El riesgo es que esa facilidad nos haga bajar la guardia.

---

### 0.4 — Hoja de Ruta

Esta es la hoja de ruta del seminario. Cinco bloques.

Estamos ante un cambio que afecta a toda la sociedad, y la 
medicina no es una excepción. Para abordarlo con rigor, la 
estructura sigue una lógica deliberada: primero veremos qué 
está pasando con la IA en medicina y qué dice la ciencia, 
después veremos las herramientas funcionar en directo, y 
finalmente pasaremos a la práctica. De la evidencia a la 
demostración, y de la demostración a la aplicación.

Empecemos por el principio.

---

### 1.0 — Bloque 1: La Ruptura

Bloque uno: La Ruptura.

He llamado a este bloque así porque lo que ha ocurrido con 
la inteligencia artificial en los últimos dos años no es una 
evolución gradual. Es una ruptura. Y antes de analizar la 
evidencia, necesitamos entender la magnitud de lo que está 
pasando.

---

### 1.1 — Encuesta Inicial

Una pregunta antes de seguir, y vale la pena ser sincero 
con uno mismo.

¿Has usado alguna herramienta de inteligencia artificial 
esta semana para algo relacionado con tu práctica clínica? 
No solo ChatGPT. Cualquier cosa: buscar información, 
redactar un informe, preparar una sesión, traducir un 
artículo...

Sea cual sea tu respuesta, guárdala. Al final del seminario 
volveremos a esta pregunta. Y veremos si tu percepción de 
lo que es "usar IA" ha cambiado después de lo que vamos a 
ver hoy.

---

### 1.2 — Pizarra (ChatGPT nov 2022)

El treinta de noviembre de dos mil veintidós, OpenAI publicó 
un tuit. Decía simplemente: "Presentamos ChatGPT". Un tuit 
y un enlace.

En cinco días, un millón de usuarios. Para ponerlo en 
perspectiva, Instagram tardó dos meses y medio en llegar a 
esa cifra. En dos meses, cien millones. Ninguna aplicación 
en la historia había crecido así. A día de hoy supera los 
ochocientos millones de usuarios activos semanales.

Ese tuit cambió las reglas del juego. No porque la 
tecnología fuese nueva, los modelos de lenguaje llevaban 
años desarrollándose, sino porque por primera vez cualquier 
persona podía hablar con una inteligencia artificial. Y eso 
incluye a nuestros pacientes, a sus familias, y a nosotros.

---

### 1.3 — Bibliometría PubMed

Este gráfico muestra las publicaciones en PubMed sobre 
inteligencia artificial y modelos de lenguaje, comparadas 
con las de COVID.

En dos mil veintitrés, la IA aparecía en una de cada 
doscientas quince publicaciones biomédicas. Hoy, una de 
cada noventa. Y el ritmo de crecimiento ya ha superado al 
que tuvo la investigación sobre COVID en su momento álgido. 
Para ponerlo en cifras: en un solo año, de dos mil 
veintitrés a dos mil veinticuatro, las publicaciones de IA 
en salud pasaron de veintitrés mil a veintiocho mil, un 
crecimiento que no muestra signos de frenarse.

Esto no es una moda pasajera. Lo que estamos viendo es un 
cambio en cómo se genera, se procesa y se aplica el 
conocimiento médico. No es solo que haya más artículos 
sobre IA. Es que la propia forma de hacer medicina basada 
en la evidencia está empezando a cambiar. Y eso nos obliga 
a replantearnos algo que dábamos por sentado: cómo 
decidimos en qué confiar.

---

### 1.4 — Dos historias reales

Voy a contar dos historias. Las dos son reales y 
seguramente similares a las vividas por muchos de vosotros.

Primera historia. Un pediatra tiene que explicar a unos 
padres que su hijo necesita una valoración por posible 
trastorno del espectro autista. Es una conversación 
delicada. Le pide al modelo de IA que le ayude a 
estructurar los puntos clave, con un lenguaje claro y 
empático, anticipando las preguntas que probablemente le 
harán. Revisa la propuesta, la ajusta a la familia 
concreta, y entra en la consulta mejor preparado. Diez 
minutos de preparación que cambian la calidad de esa 
conversación.

Segunda historia. Un modelo de IA sugiere una dosis de 
medicación. El clínico no la verifica. La referencia 
bibliográfica que cita el modelo no existe. Es inventada. 
Una alucinación.

La diferencia entre estas dos historias no es la 
herramienta. Es exactamente la misma herramienta. La 
diferencia está en cómo la usamos, para qué la usamos, y 
sobre todo, en si la evaluamos con el mismo rigor con el 
que evaluaríamos cualquier otra tecnología sanitaria antes 
de incorporarla a nuestra práctica.

Eso es exactamente lo que vamos a hacer en el siguiente 
bloque: examinar qué dice la evidencia.

---

### 2A.0 — Bloque 2A: Fundamentos

Entramos en un nuevo bloque. Y empezamos por algo que puede 
parecer árido pero que es más importante de lo que parece.

Desde febrero de dos mil veinticinco, la Ley Europea de 
Inteligencia Artificial exige que cualquier organización 
que use sistemas de IA garantice que su personal tiene un 
nivel suficiente de alfabetización en IA. No es una 
recomendación. Es una obligación legal. Y eso nos incluye 
a nosotros como profesionales sanitarios.

Así que lo que vamos a hacer ahora no es solo un glosario 
técnico. Es el mínimo necesario para entender de qué 
estamos hablando cuando hablamos de IA en nuestra consulta. 
Y para evaluar con criterio lo que viene después.

---

### 2A.1 — Glosario (9 conceptos)

Nueve conceptos. Los tenéis definidos en pantalla, así que 
voy a centrarme en lo que no dice ahí: por qué importan en 
vuestra práctica clínica.

LLM, modelo de lenguaje grande. Lo fundamental es entender 
qué hace: predice la siguiente palabra más probable 
basándose en patrones estadísticos. No comprende, no 
razona, no verifica. Predice. Para hacernos una idea de la 
escala: GPT-3 tenía ciento setenta y cinco mil millones de 
parámetros. GPT-4, un billón ochocientos mil millones. Son 
cifras difíciles de imaginar, pero retened la idea: más 
parámetros no significa más comprensión. Significa mejor 
predicción.

Prompt es la instrucción que le das al modelo. Dedicaremos 
un bloque entero a esto, pero la idea clave es sencilla: si 
le preguntas mal, responde mal. No es un buscador al que le 
lanzas dos palabras. Es una conversación donde la precisión 
de tu pregunta determina la utilidad de la respuesta.

IA generativa. Genera contenido nuevo a partir de lo que 
aprendió en su entrenamiento. Y aquí hay un concepto 
relacionado que conviene conocer: modelo fundacional. El 
término lo acuñó Stanford en dos mil veintiuno para 
describir modelos entrenados con datos masivos que luego se 
adaptan a tareas muy distintas. Pensad en los cimientos de 
un edificio: una misma base sobre la que se construyen 
aplicaciones de texto, de imagen, de audio. El concepto es 
tan importante que aparece en la legislación europea de 
inteligencia artificial.

Alucinación. Probablemente el concepto más importante de 
los nueve para un clínico. Cuando un LLM no tiene la 
respuesta, no dice "no lo sé". Genera una respuesta 
igualmente fluida, igualmente convincente, pero falsa. La 
apariencia de certeza es idéntica cuando acierta y cuando 
inventa. Por eso la verificación no es opcional.

RAG, generación aumentada por recuperación. Es la 
diferencia entre una IA que genera desde su memoria interna 
y una que primero busca en fuentes reales y luego responde. 
Herramientas como Perplexity u Open Evidence funcionan así. 
Es un paso crítico hacia un uso más seguro, y le 
dedicaremos tiempo.

IA agéntica. Una IA que no solo responde, sino que 
planifica pasos, ejecuta tareas y toma decisiones 
intermedias de forma autónoma. Ya está apareciendo en 
investigación clínica y cambiará la forma en que 
interactuamos con estas herramientas.

Y los dos nuevos que quiero que retengáis: token y ventana 
de contexto. Un token es la unidad mínima que procesa el 
modelo, algo entre una letra y una palabra. Y la ventana de 
contexto es su memoria de trabajo: cuánta información puede 
manejar a la vez en una conversación. Cuando un modelo 
"olvida" lo que le dijiste hace un rato, es porque ha 
superado su ventana de contexto. Es un límite real que 
afecta directamente a cómo lo usas en consulta: si quieres 
que analice un informe largo, necesitas saber si cabe.

Estos nueve conceptos, junto a otros neologismos que irán 
apareciendo a lo largo de esta explosión de algoritmos y 
modelos, van a ser vuestro vocabulario de trabajo. Pasemos 
a ver cómo encaja la IA en nuestro flujo de trabajo clínico.

---

### 2A.2 — Flujo Clínico con IA

Cuando hablamos de inteligencia artificial en la consulta, 
tendemos a pensar en diagnóstico. Pero la realidad es más 
amplia de lo que parece.

Esta revisión sistemática de Li y colaboradores, publicada 
en dos mil veinticinco, analizó doscientos setenta estudios 
y mapeó en qué tareas clínicas podía asistir GPT-4. El 
resultado: setenta y uno por ciento de las subtareas del 
flujo clínico, repartidas en las cinco etapas que veis en 
pantalla.

Pero no todas las etapas son iguales. Donde la IA rinde 
mejor es en documentación y en generación de texto: 
resúmenes, informes, material educativo. Donde peor, en las 
tareas que requieren integración de contexto y juicio 
clínico: planificación terapéutica, decisiones con 
incertidumbre, manejo de la complejidad del paciente real. 
Un estudio reciente con siete modelos de razonamiento 
avanzado lo confirmó: más del ochenta y cinco por ciento de 
precisión en diagnósticos simples, pero el rendimiento cae 
cuando hay que decidir qué exploración pedir o qué 
tratamiento elegir.

Retened esta idea porque va a ser recurrente: la IA es 
mejor asistente administrativo que clínico. Y eso no es una 
limitación menor. Es la clave para usarla bien.

---

### 2A.3 — ¿Qué es un LLM?

Esto es lo que necesitamos entender de verdad sobre cómo 
funciona un modelo de lenguaje.

Pensad en el texto predictivo de vuestro móvil. Cuando 
empezáis a escribir una palabra, el teléfono os sugiere la 
siguiente. Un LLM hace exactamente eso, pero a una escala 
inimaginable: entrenado con billones de textos, es capaz de 
generar párrafos enteros que suenan perfectos. Coherentes, 
fluidos, convincentes. Pero no comprende lo que dice. No 
razona. Predice.

Y aquí está la trampa para un clínico: el formato de la 
respuesta es indistinguible del de un experto. Si le 
preguntas por un diagnóstico diferencial, te lo presenta 
con la misma estructura que usaría un adjunto experimentado. 
Pero detrás no hay juicio clínico. Hay estadística. Y eso 
significa que puede afirmar algo completamente falso con la 
misma seguridad con que afirma algo correcto. No tiene 
mecanismo interno para distinguir verdad de ficción.

Esa es la razón de fondo de todo lo que veremos a partir de 
ahora en el bloque de evidencia: resultados brillantes en 
unos contextos, fallos graves en otros. Y siempre con la 
misma apariencia de certeza.

---

### 2B.0 — Bloque 2B: Evidencia Científica

Entramos en el bloque más denso del seminario. Y el más 
necesario.

Sobre IA en medicina hay mucho ruido y mucho miedo. Las dos 
posturas se basan más en titulares que en datos. Lo que 
vamos a hacer ahora es lo contrario: revisar la evidencia 
reciente. Veréis resultados que impresionan y fallos que 
asustan. A veces en el mismo artículo.

---

### 2B.1 — Human-in-the-Loop

El modelo jiuman in de lup define cómo debe funcionar la 
colaboración. La IA propone, redacta, sintetiza. El pediatra 
verifica, decide, empatiza. Son roles complementarios, no 
intercambiables.

En el ensayo clínico aleatorizado de Goh y colaboradores, 
publicado en Nature Medicine en dos mil veinticinco, los 
médicos con acceso a GPT-4 mejoraron un seis y medio por 
ciento en manejo clínico. Pero tardaron dos minutos más por 
caso. En una agenda de treinta pacientes, eso son sesenta 
minutos adicionales.

El mensaje no es "úsalo siempre." Es "úsalo donde el 
beneficio justifique el coste." En documentación, casi 
siempre. En diagnóstico de rutina, rara vez. Esa decisión 
estratégica es exactamente lo que veremos con el Modelo 
Sándwich al final.

---

### 2B.2 — Paradigma Colaboración

El paradigma de colaboración se resume así: por separado, 
médico e inteligencia artificial tienen capacidades 
complementarias pero asimétricas.

El médico aporta juicio clínico, empatía y contexto del 
paciente y su familia. La IA aporta velocidad y 
procesamiento masivo, pero con una precisión diagnóstica 
global del cincuenta y dos por ciento según el metaanálisis 
de Takita con ochenta y tres estudios, publicado en 
ene-pe-jota Digital Medicine. Traducido: acierta uno de 
cada dos diagnósticos. Es el nivel de un médico no 
especialista.

Ahora bien, juntos la cosa cambia. El metaanálisis de Wang, 
también en ene-pe-jota Digital Medicine, muestra una mejora 
de casi cinco puntos porcentuales en manejo clínico cuando 
el médico trabaja con IA. Pero, y esto es clave, la 
combinación solo funciona cuando el humano mantiene su 
criterio activo. No cuando se limita a dar "ok" a lo que la 
máquina propone. Esa diferencia entre supervisar y 
cuestionar es exactamente el tema de la siguiente 
diapositiva.

---

### 2B.3 — Paradoja H+AI

Atención a la paradoja más contraintuitiva de toda la 
sesión. Wang y colaboradores, en ene-pe-jota Digital 
Medicine dos mil veintiséis, muestran que humano más IA no 
siempre supera a la IA sola.

El riesgo relativo es de uno coma cincuenta y nueve, pero 
no significativo. Los errores persisten entre el veintiséis 
y el treinta y seis por ciento incluso con supervisión. Y 
el intervalo de predicción va de menos treinta y uno a más 
cuarenta y un puntos, una incertidumbre que hace imposible 
predecir el resultado caso por caso.

¿Por qué ocurre esto? Porque supervisar no es lo mismo que 
cuestionar. Cuando leemos una respuesta bien redactada, 
nuestro cerebro tiende a aceptarla. Es el mismo sesgo de 
anclaje que conocemos en clínica, pero amplificado por la 
elocuencia de la máquina.

Ahora bien, hay una excepción: en el ensayo clínico de Goh, 
los médicos con acceso estructurado a GPT-4 mejoraron un 
seis y medio por ciento en manejo clínico. La diferencia no 
fue el modelo, sino el diseño: integración activa, no 
supervisión pasiva. Y atención al deskilling: si un 
residente delega sistemáticamente los diagnósticos 
diferenciales a ChatGPT durante cuatro años, ¿qué ocurre 
el día que no tiene cobertura? Esa pérdida de competencia 
es acumulativa y silenciosa.

---

### 2B.4 — Sesgos Cognitivos

En la interacción humano-IA operan dos sistemas cognitivos, 
los mismos que describió Kahneman. El sistema rápido acepta 
o rechaza con poca fricción. El sistema analítico supervisa, 
corrige y justifica. El problema es que la IA está diseñada 
para reducir fricción. Y eso activa sistemáticamente el 
sistema rápido.

Tres sesgos explican buena parte de los fallos que hemos 
visto en la slide anterior. Sesgo de automatización: aceptar 
sin crítica porque la respuesta suena bien. Anclaje 
algorítmico: la primera sugerencia del modelo fija tu 
razonamiento, y a partir de ahí solo buscas confirmación. Y 
delegación progresiva: ceder autonomía poco a poco, sin 
darte cuenta, hasta que un día no sabes hacerlo sin la 
herramienta.

La regla práctica es la que veis en pantalla, y merece la 
pena retenerla: antes de mirar la salida del modelo, formula 
tu hipótesis. Después, compara, justifica y documenta. 
Porque la IA reduce fricción cognitiva, y eso es útil. Pero 
la seguridad clínica exige recuperar fricción en los puntos 
críticos.

---

### 2B.4bis — Pausa: ¿Experiencias?

(Nota: la slide mantiene "levantad la mano" para uso 
presencial. Este audio es la versión offline alternativa.)

Antes de seguir con más evidencia, una pausa. Piensa un 
momento: ¿has usado alguna vez una herramienta de IA en tu 
consulta? Y si lo has hecho, ¿verificaste la respuesta, o 
la aceptaste porque sonaba bien?

No es una pregunta retórica. Después de lo que acabamos de 
ver sobre sesgos de automatización y anclaje algorítmico, 
merece la pena ser honesto con uno mismo. Porque la mayoría 
de nosotros hemos hecho exactamente eso alguna vez: confiar 
sin verificar. Y precisamente por eso necesitamos lo que 
viene ahora: evidencia específica para calibrar dónde 
podemos confiar y dónde no.

---

### 2B.5 — Precisión Diagnóstica (deck #20)

Hablemos de números concretos. El metaanálisis más amplio 
publicado hasta ahora, Takita y colaboradores en ene-pe-jota 
Digital Medicine, ochenta y tres estudios, muestra que la 
precisión diagnóstica global de la IA es del cincuenta y dos 
por ciento. Uno de cada dos. Eso es el nivel de un médico 
no especialista, y queda quince coma ocho puntos por debajo 
del especialista.

Ahora bien, esa cifra global esconde una asimetría 
importante. En tareas acotadas, cribado de artículos, 
extracción de datos estructurados, codificación, el 
rendimiento es alto. Pero en diagnóstico complejo, donde 
hay que integrar historia, exploración y contexto familiar, 
la IA no llega. De hecho, un metaanálisis en red con ciento 
sesenta y ocho estudios confirma que en el diagnóstico más 
probable, el top uno, el humano sigue ganando.

Pensadlo así: si un padre os pregunta "¿puedo fiarme del 
diagnóstico que me ha dado ChatGPT?", la respuesta honesta 
es: "acertará la mitad de las veces, y no sabrás cuál 
mitad." Esa incertidumbre es exactamente lo que justifica 
que la IA sea copiloto, nunca piloto.

---

### 2B.8 — Alucinaciones (deck #21)

Las alucinaciones son el riesgo más crítico. Pero 
necesitamos distinguir dos tipos, porque el peligro no está 
donde parece.

El primero es el que más titulares genera: las citas 
bibliográficas inventadas. Bard fabricaba nueve de cada 
diez. GPT-4 mejora, pero aún inventa casi una de cada tres. 
Y no inventa mal: inventa autores que existen, revistas que 
existen, DOIs que parecen reales. Si no lo compruebas en 
PubMed, no lo distingues. Regla absoluta: nunca usar una 
cita de IA sin verificar el DOI en la fuente primaria.

El segundo tipo es más sutil y más relevante para nuestra 
consulta. A la derecha tenéis los datos de Asgari y 
colaboradores, publicado en ene-pe-jota Digital Medicine. Lo 
que hicieron fue poner un escriba de IA a generar notas 
clínicas a partir de transcripciones de consultas de 
atención primaria. Cuatrocientas cincuenta notas, casi trece 
mil frases, revisadas una por una por cincuenta médicos 
marcando cada error. El resultado: las alucinaciones puras 
bajan al uno y medio por ciento. Menos que el error humano 
tomando notas a mano. Pero las omisiones, lo que el modelo 
simplemente no incluye, llegan al tres y medio por ciento. 
Y eso es lo que os tiene que preocupar más, porque una 
omisión en la historia de un niño puede cambiar todo el 
razonamiento diagnóstico.

La IA miente poco. Pero omite más de lo que miente. Y ni lo 
uno ni lo otro se ve a simple vista. Por eso verificar no es 
un consejo. Es la regla de oro.

---

### 2B.8bis — Brecha Exámenes vs Clínica (deck #22)

Los modelos de lenguaje obtienen entre ochenta y cuatro y 
noventa por ciento en exámenes tipo USMLE. Impresionante. 
Pero en práctica clínica real, la precisión global cae al 
cincuenta y dos por ciento según el metaanálisis de Takita 
con ochenta y tres estudios.

¿Por qué esa caída? Porque un examen tiene una respuesta 
correcta entre cinco opciones. La consulta real tiene ruido: 
un niño que llora y no se deja explorar, unos padres que 
olvidan mencionar que el abuelo tiene celiaquía, una 
otoscopia con cerumen que no deja ver. Nada de eso aparece 
en los datos de entrenamiento.

Y el dato que más debería preocuparnos: solo el nueve coma 
cuatro por ciento de los estudios publicados sobre IA 
clínica evalúa errores y daño potencial al paciente. Más 
del noventa por ciento de la investigación mide si la IA 
acierta, pero casi nadie mide cuándo hace daño.

Si no medimos el daño, no podemos prevenirlo. Y eso nos 
lleva directamente a la siguiente pregunta: qué ocurre 
cuando son las familias las que consultan a la IA.

---

### 2B.9 — Riesgo: Dr. AI (deck #23)

Esto me preocupa especialmente como clínico. No por 
nosotros, sino por lo que hacen las familias cuando no 
estamos delante.

Los datos que veis hablan por sí solos. En un estudio con 
veintidós escenarios pediátricos de emergencia, ChatGPT y 
GPT-4 dieron instrucciones de primeros auxilios correctas 
en menos de la mitad de los casos. Y el consejo de llamar 
a emergencias fue correcto en solo uno de cada dos 
escenarios. En un segundo estudio centrado exclusivamente 
en reanimación cardiopulmonar pediátrica, menos del diez 
por ciento de las respuestas cumplía las guías de la 
American Heart Association.

Pensad en la escena: una madre a las tres de la madrugada, 
el niño atragantado, el móvil en la mano. La respuesta 
puede sonar impecable. Y puede estar equivocada en lo que 
importa: la posición, la fuerza, la secuencia.

Nuestra responsabilidad no es solo usar bien la IA. Es 
educar activamente a las familias sobre sus limitaciones. 
Ante una emergencia, llama al ciento doce. La IA no salva 
vidas. El ciento doce sí.

---

### 2B.9bis — NMA JMIR: Ningún modelo gana en todo (deck #24)

El meta-análisis en red más amplio publicado en JMIR hasta 
ahora reúne ciento sesenta y ocho estudios y casi treinta y 
seis mil preguntas clínicas. La pregunta central: ¿qué 
modelo es mejor para qué?

La respuesta es que ninguno gana en todo. Para preguntas 
objetivas, ChatGPT-cuatro-o. Para preguntas abiertas, 
ChatGPT-cuatro. Para triaje y clasificación, Gemini. 
Distintas tareas, distintos ganadores.

Pero en diagnóstico top-uno, donde hay que acertar a la 
primera como hacemos cada día en consulta, los expertos 
humanos siguen en cabeza. Un SUCRA de cero con noventa es 
la probabilidad más alta de ocupar el primer puesto en el 
ranking. Ningún modelo lo supera en esa tarea.

La implicación práctica es directa: no existe un modelo 
universal. Para buscar evidencia, uno. Para redactar, otro. 
Para clasificar, otro. Y para lo más crítico, la primera 
sospecha diagnóstica, vuestro criterio sigue siendo el más 
difícil de superar.

---

### 2B.11 — RAG y sesgo (deck #25)

¿Y si usamos RAG para evaluar sesgo? La lógica es 
impecable: si el modelo trabaja con fuentes verificadas, 
¿no debería juzgar mejor la calidad de un estudio?

Los datos dicen que no. Cuando se evaluó NotebookLM para 
valorar riesgo de sesgo en estudios clínicos, la 
concordancia con revisores humanos fue muy baja. El 
coeficiente de correlación intraclase fue de cero coma 
veintisiete, que en metodología se clasifica directamente 
como acuerdo pobre. Y el porcentaje de coincidencia directa 
con los revisores osciló entre el catorce y el veintinueve 
por ciento, según la dimensión evaluada. Menos de uno de 
cada tres juicios coincidía con el experto.

¿Por qué falla incluso con RAG? Porque evaluar sesgo no es 
procesar texto, es inferir lo que el artículo no dice. 
¿Por qué no reportan el seguimiento completo? ¿Por qué el 
grupo control tiene una distribución de edad distinta? Ese 
razonamiento metacrítico es experiencia metodológica, no 
lingüística. Ninguna fuente verificada lo puede suplir.

Recordad este dato cuando lleguemos al semáforo: evaluar 
calidad de evidencia es zona roja, con RAG o sin él.


### HTML aplicados
1. Textos en inglés → español: "poor agreement" → "acuerdo pobre", 
   "percent agreement" → "acuerdo porcentual", 
   "ranged from 14.8% to 29.6%" → "entre el 14,8% y el 29,6%"
2. Año corregido: JPOSNA 2025 → JPOSNA 2026 (vol. 14, 2026)
3. Añadida nota al pie post-refs: definición RAG en 1 línea, 
   font-size 0.52em, opacity 0.7, sin glass-panel

### Audio: corrección pendiente
- "estudios clínicos" → "estudios observacionales" (más preciso)

### Dato en recámara (no incluido en audio)
- Discrepancia interna en paper: ICC 0.27 (body/abstract) vs 0.35 
  (Table 1). Usamos 0.27 (conservador). Tener preparado por si 
  preguntan en sala.
- NotebookLM inconsistente consigo mismo entre trials (ICC 0.41-0.54). 
  Conecta con 2B.13 (reproducibilidad). No añadido al audio por timing.

### Audio: veredicto
- Estructura assertion→evidence→implication→bridge OK
- Gancho retórico ("la lógica es impecable") validado
- Explicación del "por qué falla" (inferencia metacrítica) es el 
  punto fuerte
- Puente al semáforo limpio
- ~50s, no requiere recorte

---
### 2B.12 — Diagnóstico Pediátrico (deck #26)

Zoom al diagnóstico pediátrico. Tres estudios, dos historias 
muy distintas.

Primera historia: donde la IA se acerca. Mansoor y 
colaboradores entrenaron un modelo GPT-3 específicamente con 
quinientos encuentros pediátricos de centros rurales en 
Luisiana. Resultado: ochenta y siete coma tres por ciento de 
precisión, frente al noventa y uno coma tres del pediatra. 
Diferencia no significativa. Ojo: no es un chatbot genérico. 
Es un modelo ajustado con datos locales. Y en urgencias 
pediátricas, Del Monte evaluó ChatGPT-cuatro-o con ochenta 
casos reales en Turín y obtuvo una puntuación superior a la 
de los pediatras de urgencias. En tareas acotadas, con datos 
estructurados, la IA compite.

Segunda historia: donde falla. Sun y colaboradores evaluaron 
tres modelos con casi diez mil pacientes psiquiátricos en 
seis centros de China. Hallazgo clave: la precisión de 
GPT-cuatro fue del sesenta y uno por ciento en adolescentes 
y del setenta y nueve por ciento en mayores de sesenta. 
Dieciocho puntos de diferencia. Y en trastornos 
conductuales de la infancia, la categoría que más os afecta, 
solo el cuarenta y cinco por ciento de acierto. Menos de la 
mitad.

El patrón es claro y merece la pena retenerlo: cuanto más 
estructurada la tarea, mejor rinde la IA. Cuanto más juicio 
clínico requiere, y cuanto más joven es el paciente, más 
lejos queda del especialista. Y atención, porque incluso 
donde se acerca, la velocidad no garantiza la fiabilidad. 
Eso es lo que veremos ahora.

2B.13 — Rápido ≠ fiable ≠ consistente (deck #27)
Tres estudios recientes, tres lecciones, para entender por
qué velocidad, fiabilidad y consenso son cosas distintas. Y
por qué confundirlas es el error más frecuente cuando
evaluamos IA.
Velocidad. En escoliosis adolescente, cuatro modelos de
lenguaje clasificaron radiografías cien veces más rápido que
los cirujanos: segundos frente a once o doce minutos. Pero
cuando se repitió exactamente la misma prueba una semana
después, con las mismas imágenes y las mismas instrucciones,
los modelos dieron resultados distintos. Kappa prácticamente
cero. Es decir: el mismo paciente puede recibir una
clasificación diferente según el día. La velocidad no compró
reproducibilidad.
Fiabilidad. En otorrinolaringología pediátrica,
ChatGPT-cuatro alcanzó kappa de uno en adherencia a guías
clínicas de tubos de timpanostomía. Perfección. Pero cuando
se evaluó la misma categoría de herramienta para generar
citas bibliográficas en radiología, la tasa de referencias
inventadas osciló entre el tres y el sesenta y uno por
ciento, según el modelo. Veinte veces más error de un modelo
a otro. Perfecto donde la respuesta está codificada en una
guía. Impredecible donde tiene que construir la respuesta.
Consenso. Los cirujanos expertos coinciden el noventa y dos
por ciento de las veces. Los modelos de lenguaje, entre el
uno con seis y el diez con dos por ciento. Eso es acuerdo
por azar. Como lanzar una moneda.
La misma tecnología. Tres dimensiones. Tres perfiles de
fallo completamente distintos. Y la clave: en ninguna de las
tres puedes predecir cuándo va a fallar. Eso tiene
consecuencias directas en cómo leemos los sesgos que genera,
que es lo que vemos ahora.
HTML aplicados (2B.13)

Panel Fiabilidad: "91.4% fabricadas (Bard)" → "3-61% fabricadas
según modelo (Güneş 2025)" — evita repetición con 2B.8
Source-note: "ORL 2025" → "ORL 2026" (Durgut 2026;283:117-130)
Source-note rediseñada: más ancha, una sola línea, con autores
y revista completa (Aktan · Durgut · Güneş)
Warning boxes: texto ligeramente ampliado para autoexplicarse
sin audio (ej: "acuerdo por azar", "según modelo")
data-audio-text actualizado con v3 didáctica

Audio: veredicto (2B.13)

Estructura: gancho → velocidad (dato + implicación) → fiabilidad
(paradoja + rango) → consenso (contraste + traducción) → cierre + puente
~68s. Más largo que media pero justificado: 3 estudios, 3 conceptos,
audiencia que no ha leído los papers
Cada dato tiene su "traducción clínica" (ej: "el mismo paciente puede
recibir clasificación diferente según el día")
"Como lanzar una moneda" = ancla memorable para κ≈0
Puente a 2B.15 (Sesgos Algorítmicos) limpio
TTS: sin siglas problemáticas, números en letra

DUDA PENDIENTE — resolver antes de cerrar deck
La slide 2B.14 del mapa original ("Consenso Clínico", imagen
IA_Potencia_06, línea HTML 2053) muestra los mismos datos que el
panel 3 de esta slide: expertos 92% κ=0.913 vs LLMs 1.6-10.2% κ≈0.
Si 2B.14 sigue en el HTML como slide independiente, hay duplicación
directa. Opciones:
a) Eliminar 2B.14 y que esta slide absorba todo el contenido
b) Reconvertir 2B.14 en otra cosa (ej: detalle por modelo, o
"confident failures" como caso cualitativo)
c) Mantener ambas si el ritmo narrativo lo justifica
→ Ernesto debe decidir revisando el HTML de 2B.14.
Refs verificadas — añadir:
| Aktan 2025, Diagnostics 15:3219 | 2B.13 | 125 AIS, 4 LLM, κ 0.001-0.036 vs cirujanos 0.913, test-retest azar | ✅ |
| Durgut 2026, Eur Arch Otorhinolaryngol 283:117-130 | 2B.13 | 16 escenarios tubos timpanostomía, ChatGPT-4.0 96.8%, 100% con prompt "current literature" | ✅ |
| Güneş 2025, Diagn Interv Radiol; DOI:10.4274/dir.2025.253101 | 2B.13 | 480 refs, Claude 3.5 Sonnet 80.8% exactas / 3.1% fabricadas, Gemini 60.6% fabricadas | ✅ |

### HTML aplicados (2B.12)
1. Slide completamente rediseñada: grid-3 → grid-2
2. Panel central "Mensaje de encaje" eliminado
3. Panel izq: Mansoor rural (87.3% vs 91.3%) + Del Monte urgencias (72.5 vs 61.9)
4. Panel der: Sun gradiente edad (61%→79%, P<.001) + F9 44.9%
5. Barra Patrón: max-width 980px, font-size 0.92em
6. Source-note: links DOI corregidos, separador · en vez de |
7. Atribución corregida: "Del Monte 2025" → "Mansoor 2025" para dato rural

### Audio: veredicto (2B.12)
- Estructura assertion→evidence (×3 estudios)→pattern→bridge OK
- ~65s, ligeramente más largo que media pero justificado por 3 fuentes
- Fine-tuning explicitado ("no es un chatbot genérico")
- Puente a 2B.13 (velocidad ≠ fiabilidad) limpio
- TTS: "ChatGPT-cuatro-o", "GPT-cuatro", números en letra

---

### REFERENCIAS VERIFICADAS — añadir filas:
| Mansoor 2025, JMIRx Med 6:e65263 | 2B.12 | GPT-3 fine-tuned rural, 87.3% vs 91.3%, P=.47, 500 casos Louisiana | ✅ |
| Del Monte 2025, Front Digit Health; DOI:10.3389/fdgth.2025.1624786 | 2B.12 | Urgencias ped Turín, ChatGPT-4o 72.5 vs pediatras 61.9, 80 casos | ✅ |
| Sun 2026, JMIR Med Inform 14:e77699 | 2B.12 | 9.923 pac psiq 6 centros, GPT-4.0 61% adolesc vs 79% ≥60a, F9 44.9% | ✅ |

### CORRECCIONES HTML PENDIENTES — eliminar:
- (Ya no aplica) "Slide 2B.12: pie Del Monte 2025 → Mansoor 2025" — resuelta en rediseño completo

### NOTAS PARA CONTINUIDAD — añadir:
- Slide 2B.12 rediseñada de raíz: antes 3 paneles (rural + "ve slide anterior" + salud mental F1), ahora 2 paneles (tareas acotadas vs pacientes jóvenes). Tesis: "depende del contexto"
- El dato F1 0.41→0.655 de Sun 2026 es macro-F1 lenient de GPT-3.5 vs GPT-4.0 en TODAS las categorías psiquiátricas ICD-10, NO es mejora en salud mental pediátrica. Eliminado de la slide
- Mansoor usa GPT-3 DaVinci fine-tuned, no genérico. Crítico para interpretar el 87.3%
- Sun 2026 (no 2025): publicado 13 enero 2026 en JMIR Med Inform vol. 14
- "Psiquiatría 2025" como referencia eliminada — era Sun 2026 mal citado

---

### 2B.13 — Rápido ≠ fiable ≠ consistente (deck #27)

Tres estudios recientes, tres lecciones, para entender por qué velocidad, fiabilidad y consenso son cosas distintas. Y por qué confundirlas es el error más frecuente cuando evaluamos IA. Velocidad. En escoliosis adolescente, cuatro modelos de lenguaje clasificaron radiografías cien veces más rápido que los cirujanos: segundos frente a once o doce minutos. Pero cuando se repitió exactamente la misma prueba una semana después, con las mismas imágenes y las mismas instrucciones, los modelos dieron resultados distintos. Kappa prácticamente cero. Es decir: el mismo paciente puede recibir una clasificación diferente según el día. La velocidad no compró reproducibilidad. Fiabilidad. En otorrinolaringología pediátrica, ChatGPT-cuatro alcanzó kappa de uno en adherencia a guías clínicas de tubos de timpanostomía. Perfección. Pero cuando se evaluó la misma categoría de herramienta para generar citas bibliográficas en radiología, la tasa de referencias inventadas osciló entre el tres y el sesenta y uno por ciento, según el modelo. Veinte veces más error de un modelo a otro. Perfecto donde la respuesta está codificada en una guía. Impredecible donde tiene que construir la respuesta. Consenso. Los cirujanos expertos coinciden el noventa y dos por ciento de las veces. Los modelos de lenguaje, entre el uno con seis y el diez con dos por ciento. Eso es acuerdo por azar. Como lanzar una moneda. La misma tecnología. Tres dimensiones. Tres perfiles de fallo completamente distintos. Y la clave: en ninguna de las tres puedes predecir cuándo va a fallar. Eso tiene consecuencias directas en cómo leemos los sesgos que genera, que es lo que vemos ahora.

### Notas 2B.13
- HTML: Panel Fiabilidad: "91.4% fabricadas (Bard)" → "3-61% fabricadas según modelo (Güneş 2025)" — evita repetición con deck #21 (Alucinaciones)
- Source-note: "ORL 2025" → "ORL 2026" (Durgut 2026;283:117-130)
- Source-note rediseñada: más ancha, una sola línea, con autores y revista completa (Aktan · Durgut · Güneş)
- ~68s. Más largo que media pero justificado: 3 estudios, 3 conceptos
- DUDA PENDIENTE: La slide 2B.14 del mapa original ("Consenso Clínico", imagen IA_Potencia_06, línea HTML 2053) muestra los mismos datos que el panel 3 de esta slide (expertos 92% κ=0.913 vs LLMs 1.6-10.2%). Si 2B.14 sigue en el HTML como slide independiente, hay duplicación directa. Decidir revisando el HTML.

---

### 2B.15 — Sesgos Algorítmicos (deck #28)

Los sesgos algorítmicos son un riesgo que debemos entender como clínicos, no solo como usuarios. Y los datos lo respaldan: según una revisión en ene-pe-jota Digital Medicine, la mitad de los estudios de inteligencia artificial sanitaria publicados hasta ahora presentan alto riesgo de sesgo. Solo uno de cada cinco tiene riesgo bajo. Aparecen en tres niveles, y cada uno tiene una consecuencia clínica distinta. En la entrada: los datos de entrenamiento pueden no representar a nuestra población. Un modelo entrenado mayoritariamente con datos de niños anglosajones puede infradiagnosticar dermatitis en piel oscura o malinterpretar patrones culturales de presentación del dolor. En el proceso: la selección automatizada amplifica patrones preexistentes. Si los datos históricos muestran menos derivaciones de TDAH en niñas, el modelo aprenderá que el TDAH es cosa de niños y perpetuará el infradiagnóstico. Y en la salida: las alucinaciones se presentan con alta confianza, sin señales de alerta. No hay un indicador luminoso que diga esto me lo estoy inventando. La validación en poblaciones infrarrepresentadas no es un ideal, es una necesidad clínica. Lo que funciona en un hospital universitario de Boston no necesariamente aplica en un centro de salud de Alcorcón. Y eso nos lleva a una pregunta práctica: qué tareas podemos delegar con seguridad y cuáles no. Eso es exactamente lo que clasifica el semáforo que viene ahora.

### Notas 2B.15
- HTML rediseñado: imagen IA_Potencia_08.jpg eliminada → 3 paneles HTML (input/proceso/output)
- Imagen IA_Potencia_08.jpg queda libre como reserva
- Refs corregidas: Value in Health 2025 + Diagnostics 2025 → Hasanzadeh npj Digit Med 2025 (DOI:10.1038/s41746-025-01503-7)
- Dato "50% alto riesgo sesgo, 20% bajo" = Kumar et al. 2023, citado dentro de Hasanzadeh
- El dato "17% inferior en minorías étnicas" del arsenal NO tiene fuente primaria verificable — no usar
- A4SLR (Lee, Value in Health 2025): reservar para deck #29 (Semáforo IA, zona verde, F1 screening 0.917-0.977)
- Aktan (Diagnostics 2025): ya usada en deck #27, no repetir aquí

---

### 2B.16 — Semáforo IA (deck #29)

Os presento un semáforo de seguridad basado en toda la evidencia que hemos revisado. Y quiero que entendáis no solo los colores, sino por qué cada tarea está donde está. Luz verde: automatizar con supervisión tareas como cribado de artículos, extracción de datos tabulares y generación de resúmenes estructurados. ¿Por qué verde? Porque son tareas donde el error es detectable y reversible. Si el modelo extrae mal un dato de una tabla, lo ves al revisar. De hecho, en revisiones sistemáticas asistidas por IA, el cribado alcanza una efe-uno de cero coma noventa y dos a cero coma noventa y ocho. Luz amarilla: borradores de informes, síntesis de historiales y apoyo al diagnóstico diferencial. ¿Por qué amarillo? Porque el error puede pasar desapercibido si no cuestionas activamente. Recordad la paradoja de Wang: supervisar no es lo mismo que cuestionar. Y las omisiones, lo que el modelo simplemente no incluye, llegan al tres y medio por ciento. Son invisibles si no buscas lo que falta. Luz roja: diagnóstico primario de imagen, dosificación sin verificación, decisiones clínicas irreversibles. ¿Por qué rojo? Porque el error tiene consecuencias irreversibles para el paciente y no siempre es detectable a tiempo. Ya hemos visto que la reproducibilidad en clasificación es kappa prácticamente cero. Fijaos en que el criterio no es la IA lo hace bien o mal. El criterio es: si se equivoca, ¿puedo detectarlo antes de que cause daño? Esa es la pregunta que determina el color.

### Notas 2B.16
- Imagen IA_Potencia_09.jpg reemplazada por tabla HTML semáforo 3 columnas (verde/amarillo/rojo)
- Imagen IA_Potencia_09.jpg queda libre como reserva
- Assertion: "Si la IA se equivoca, ¿puedes detectarlo a tiempo?" — criterio = detectabilidad del error
- Métricas embebidas: F1 0.92-0.98 (verde), omisiones 3.5%/precisión 52%/ICC 0.27 (amarillo), κ≈0/<10% AHA (rojo)
- Source-note con DOI hyperlinks: Lee · Asgari · Takita · Beber · Aktan · Bushuven
- ~70s. Slide de síntesis que integra todo el bloque 2B
- HTML definitivo en: slide_2B16_semaforo_DEFINITIVO.html


---

### 2B.18 — Marco Legal: Lo que necesitas saber (deck #30)

Antes de pasar a las aplicaciones prácticas, el marco legal. Voy a ser directo porque esto es más sencillo de lo que parece.

La norma que manda hoy es el RGPD. El Reglamento Europeo de Inteligencia Artificial clasifica la IA diagnóstica como alto riesgo, pero su calendario está en transición. Lo que sí está en vigor desde febrero de dos mil veinticinco es la obligación de alfabetización en IA. Es decir: formarse no es opcional.

Y la Asociación Médica Mundial, en Porto, octubre de dos mil veinticinco, acuñó un principio que lo resume: PITL, Physician In The Loop. El médico retiene la autoridad final sobre cualquier output de IA que afecte al cuidado clínico. Eso tiene dos caras: si sigues una recomendación errónea sin verificarla, la responsabilidad es tuya. Pero no usar herramientas que forman parte del estándar de cuidado también puede ser cuestionable.

Lo práctico. A la izquierda tenéis tres niveles según qué datos introduces. Verde: sin datos del paciente. Hojas para familias, sesiones clínicas, traducciones. Aquí vale cualquier IA comercial. Revisad siempre el output.

Amarillo: datos clínicos desidentificados. Diagnóstico diferencial, consulta sobre manejo. Lo clave aquí es cómo desidentificas. Os propongo seis pasos que se hacen en medio minuto: nombres fuera, edad por rango, fechas relativas en vez de absolutas, sin geografía, y en enfermedades raras, describir el mecanismo fisiopatológico, nunca nombrar la enfermedad, porque el propio diagnóstico puede identificar al paciente. Además, usad la configuración de privacidad de la herramienta: en ChatGPT se llama Chat Temporal, en Claude es la conversación de incógnito, en Gemini se desactiva la actividad de Gemini Apps. Y en todas podéis desactivar por separado el uso de vuestros datos para entrenar el modelo.

Rojo: datos identificables o imágenes clínicas. Aquí, solo herramientas institucionales integradas en la historia clínica electrónica.

A la derecha, dos cosas. Primero, dónde van vuestros datos. No es lo mismo. Local o europeo, máximo control. Proveedores americanos, con un acuerdo de adecuación vigente pero apelado ante el Tribunal de Justicia. Proveedores chinos como DeepSeek, esencialmente incompatibles con el RGPD para datos de salud. Italia los prohibió en enero de dos mil veinticinco.

Y segundo, un checklist de seis preguntas antes de usar cualquier IA en un contexto clínico. Lo tenéis en pantalla.

El mensaje de cierre es el que veis abajo: usar IA es legal y puede llegar a ser exigible, pero desidentifica, documenta, y mantén el juicio crítico. La lex artis no cambia. Cambia la herramienta.

### Notas 2B.18
- Slide consolidada: fusión de 2B.18 (Marco Legal) + 2B.19 (Privacidad Pediátrica) + 2B.20 (Jurisdicciones y Checklist)
- Resultado neto: -2 slides (de 71 a 69). Bloque 2B: de 21 a 19 slides
- "Desidentifica en 30"" = mnemónico propio del seminario, no estándar publicado
- Privacidad por plataforma: ChatGPT = Chat Temporal, Claude = Incógnito, Gemini = Actividad Apps OFF. Ajuste entrenamiento independiente en las tres
- Tooltips: abbr-tip sustituido por title nativo (evita corte en bordes pantalla)
- DPF: validado por Tribunal General sep 2025, apelado Latombe 31 oct 2025 ante TJUE
- Digital Omnibus (propuesta nov 2025): retrasa alto riesgo AI Act. En trámite feb 2026
- ~95s. Más largo que media pero absorbe 3 slides. Recortable eliminando párrafo jurisdicciones (~15s)
```

**5. REFERENCIAS VERIFICADAS (añadir fila):**
```
| Lee 2025, Value Health 28(11):1655-1664; DOI:10.1016/j.jval.2025.08.002 | 2B.16 (deck #29) | A4SLR: F1 screening 0.917-0.977, extracción 0.96-0.998, RoB κ 0.84-0.91 | ✅ |
```
Y actualizar columna "Slide" en Takita, Asgari, Aktan y Bushuven añadiendo ", 2B.16".

**6. NOTAS PARA CONTINUIDAD (añadir):**
```
- Imagen IA_Potencia_09.jpg libre como reserva tras rediseño deck #29
- Slide 2B.16: la "paradoja de Wang" (supervisar ≠ cuestionar) se refuerza aquí como criterio zona amarilla. Conecta con 2B.3 y 2B.4
- Lee Value Health 2025: A4SLR pipeline para RS. Datos usados solo en zona verde (cribado + extracción)
- Próxima slide: 2B.17 Gaps Críticos (deck #30)

## REFERENCIAS VERIFICADAS (para defensa en sala)

| Ref | Slide | Dato clave | Estado |
|-----|-------|-----------|--------|
| Takita 2025, npj Digit Med 8:175 | 2B.2, 2B.5 | 83 estudios, 52.1% precisión IA | ✅ |
| Wang G 2026, npj Digit Med | 2B.2, 2B.3 | MD +4.88pp (k=2), RR 1.59 NS, PI enorme | ✅ |
| Wang L 2025, JMIR 27:e64486 | 2B.5, 2B.9bis | NMA 168 arts, humano gana top-1 dx | ✅ |
| Goh 2025, Nat Med 31:1233 | 2B.1, 2B.3 | +6.5% manejo, +119s/caso, n=92 médicos | ✅ |
| Goh 2024, JAMA Netw Open 7:e2440969 | 2B.4 | LLM NO mejoró dx reasoning | ✅ |
| Li H 2025, JMIR 27:e71916 | 2A.2 | 270 estudios, 5 etapas, 71% subtareas | ✅ |
| Chelli 2024, JMIR 26:e53164 | 2B.8 | Bard 91.4%, GPT-3.5 39.6%, GPT-4 28.6% | ✅ |
| Asgari 2025, npj Digit Med 8:274 | 2B.8 | 1.47% alucinaciones, 3.45% omisiones, 50 revisores | ✅ |
| Del Monte 2025, Front Digit Health | 2B.5 | Urgencias pediátricas Turín, GPT-4o 72.5/80 | ✅ |
| MedR-Bench 2025, Nat Comms | 2A.2 | >85% dx simple, cae en planning | ✅ |
| Bushuven 2023, J Med Syst 47:123 | 2B.9 | Primeros auxilios correctos 45.5%, EMS correcto 54.5% | ✅ |
| Kular & Kumar 2025, Cureus; DOI:10.7759/cureus.89234 | 2B.9 | <10% conformidad AHA RCP pediátrica | ✅ |
| Beber et al. JPOSNA 2025 | 2B.11 | ICC 0.27, 14.8-29.6% agreement NotebookLM vs revisor | ✅ |

| Mansoor 2025, JMIRx Med 6:e65263 | 2B.12 (deck #26) | GPT-3 fine-tuned rural, 87.3% vs 91.3%, P=.47, 500 casos Louisiana | ✅ |
| Sun 2026, JMIR Med Inform 14:e77699 | 2B.12 (deck #26) | 9.923 pac psiq 6 centros, GPT-4.0 61% adolesc vs 79% ≥60a, F9 44.9% | ✅ |
| Aktan 2025, Diagnostics 15:3219 | 2B.13 (deck #27) | 125 AIS, 4 LLM, κ 0.001-0.036 vs cirujanos 0.913, test-retest azar | ✅ |
| Durgut 2026, Eur Arch Otorhinolaryngol 283:117-130 | 2B.13 (deck #27) | 16 escenarios tubos timpanostomía, ChatGPT-4.0 100% con prompt | ✅ |
| Güneş 2025, Diagn Interv Radiol; DOI:10.4274/dir.2025.253101 | 2B.13 (deck #27) | 480 refs, Claude 3.5 Sonnet 3.1% fabricadas, Gemini 60.6% fabricadas | ✅ |
| Hasanzadeh 2025, npj Digit Med 8:154; DOI:10.1038/s41746-025-01503-7 | 2B.15 (deck #28) | 50% estudios IA alto RoB, 20% bajo (cita Kumar 2023) | ✅ |

8. ~~Slide 2B.15 (deck #28): refs Value in Health + Diagnostics → Hasanzadeh npj Digit Med 2025. ✅~~
9. Slide 2B.14 del mapa ("Consenso Clínico", línea HTML 2053): posible duplicación con panel 3 de deck #27. Decidir si eliminar, reconvertir o mantener




## CORRECCIONES HTML PENDIENTES

1. Slide 2B.4: pie "JAMA Intern Med 2024" → "JAMA Netw Open 2024"
2. Slide 2B.3 panel izq: PI (−31.65 a +41.42) pertenece a composite scores (MD +4.88), no a RR 1.59
3. Slide 2A.2: pie "Appl Clin Inform 2025" → "JMIR 2025;27:e71916" (ref alucinada)
4. Slide 2B.9: HTML actualizado. Pan et al. Lancet 2025 eliminado → Bushuven JMS 2023 + Kular Cureus 2025. Imagen eliminada, gráfico inline. Título: "puede fallar". ✅
5. Slide 2B.8bis: verificar ref pie "Zhang 2026" (9.4%) — posible Clusmann JAMA Netw Open 2025 como alternativa
6. Slide 2B.9bis (NMA): confirmar autoría Wang L vs Gong et al. antes de cerrar — afecta source-note del HTML
7. Slide 2B.11 (RAG sesgo): citas en inglés en visual ("poor agreement", "ranged from 14.8% to 29.6%") → traducir o eliminar para TTS

10. ~~Sub-bloque regulatorio 2B.18-20 (381 líneas, 3 slides densas)~~ → Resuelto: 1 slide consolidada ~100 líneas. Tooltips con title nativo.

## NOTAS PARA CONTINUIDAD

- Dos Goh distintos: JAMA Netw Open 2024 (dx reasoning, negativo) vs Nat Med 2025 (management +6.5%, positivo)
- Estilo Feynman: una tesis por slide, cada dato la construye. Describir estudios en una línea antes de dar resultados
- La slide 2B.4 planta la semilla de "deliberación pre-algorítmica" sin nombrarla → se cierra en 5.1 (Sándwich)
- El Wang npj 2026 tiene solo k=2 estudios para +4.88pp y PI de −31.65 a +41.42 → "preliminary yet highly uncertain"
- PRINCIPIO: no usar "último/más reciente/actual" (caduca). Encuadre lectura crítica: "según este estudio..." No elevar un estudio a categoría de verdad
- Pan et al. Lancet Digit Health 2025 (89.5% errores RCP) NO encontrado en ninguna base de datos tras búsqueda exhaustiva. Sustituido por Bushuven 2023 + Kular 2025
- SUCRA no es tasa de acierto: es probabilidad de ranking. No traducir como precisión diagnóstica directa
- A4SLR (Lee, Value in Health 2025): reservar para deck #29 (Semáforo IA) como soporte zona verde
- Imagen IA_Potencia_08.jpg libre como reserva tras rediseño deck #28
- El dato "17% inferior en minorías étnicas" del arsenal NO tiene fuente primaria verificable
- Slides 2B.19 y 2B.20 del mapa original ELIMINADAS. Contenido absorbido en 2B.18 consolidada
- "Protocolo 30"" renombrado a "Desidentifica en 30"" — es mnemónico propio, no estándar
- "Modo efímero" eliminado del vocabulario → "sin historial ni entrenamiento" + nombres reales por plataforma
- "Anonimizar" → "desidentificar" en todo el sub-bloque regulatorio (técnicamente más preciso)
- Si Digital Omnibus se aprueba antes del congreso: actualizar subtitle (AI Act timeline)
- Si TJUE invalida DPF antes del congreso: mover US a rojo en jurisdicciones
- Dato Orphanet 75% reidentificación: disponible en tooltip zona roja si preguntan



# DELTA: Añadir al final de guiones_audio_definitivos_actualizado.md
# Fecha: 2026-02-20
# Contexto: Consolidación integral Bloques 2C–5

---

## ACTUALIZACIONES 2026-02-20

### Consolidación estructural aprobada
- Bloque 2C: 21→10 slides. Absorbe contenido teórico del antiguo Bloque 3 (Pirámide 5.0, catálogo herramientas, RECORD como método, GPTs/Gems)
- Bloque 3: 7→3 slides. Solo demos reales (NotebookLM + Constructor)
- Bloques 4-5: sin cambios estructurales
- Total presentación: 67→52 slides. Timing estimado: ~114 min (margen 6 min)
- Documento maestro: estructura_definitiva_2C_5.md

### Verificaciones de referencia ejecutadas
- Callens S. Acta Clin Belg. 2026;1-12. DOI: 10.1080/17843286.2026.2613903. Verificado en PubMed (PMID: 41524451). Narrative review, 4 elementos prompt + RTF + BRAIN frameworks. Ya no "sin DOI canónico"
- Liu S et al. JAMIA. 2025;32(4):605-615. DOI: 10.1093/jamia/ocaf008. Verificado en PubMed (PMID: 39812777). 20 estudios, OR=1.35. ⚠️ Slide actual dice "Nat Med" — ERROR, debe decir "JAMIA"
- Zhao J et al. BMC Med Inform Decis Mak. 2025;26:29. DOI: 10.1186/s12911-025-03324-w. Verificado en PubMed (PMID: 41444884). 23 incluidos, 14 en pooled MA (SMD=-0.71). Publicado 24 dic 2025, vol.26 (2026). Citar como 2025;26:29

---

## NUMERACIÓN DEFINITIVA POST-CONSOLIDACIÓN

### Bloques cerrados (sin cambios)
| Slide | Deck# | Estado |
|-------|:---:|:---:|
| 0.1–2B.18 | #1–#30 | ✅ Audio cerrado |

### Bloque 2C: "De la Evidencia a la Práctica" (10 slides)
| Slide nueva | Deck# | Origen antiguo | Estado |
|------------|:---:|:---:|:---:|
| 2C.0 Portada | #31 | 2C.0 (#31) | 🔧 Actualizar subtítulo (15→25 min) |
| Documentación: evidencia sólida | #32 | Fusión #32+#39+#40 | 🔧 HTML complejo (2 paneles + caveat) |
| Aplicaciones por dominio | #33 | Fusión #41-#45 | 🔧 Tabla HTML 5 dominios |
| Matriz de madurez | #34 | #46 rediseñada | 🔧 Imagen → tabla HTML |
| Prompt Engineering clínico | #35 | Fusión #34+#35+#36+#45+3.4 | 🔧 HTML sin errata + RECORD |
| Pirámide 5.0 + Ecosistema | #36 | Fusión 3.1+3.2+2C.6+2C.7 | 🔧 Pirámide + catálogo herramientas |
| GPTs, Gems, personalización | #37 | 3.5 migrada | 🔧 Migrar a 2C |
| RAG + Whitelisting | #38 | Fusión #47+#48 | 🔧 HTML + corregir Nat Med→JAMIA |
| Semáforo AP | #39 | #50 | 🔧 Diferenciar de #29 |
| Síntesis: 5 mensajes | #40 | #51 reescrita | 🔧 Alinear con 5 decisiones |

### Bloque 3: "Demo en Vivo" (3 slides)
| Slide | Deck# | Origen | Estado |
|-------|:---:|:---:|:---:|
| 3.0 Portada demos | #41 | 3.0 (#52) simplificada | 🔧 Solo demos reales |
| Demo: NotebookLM | #42 | 3.3 (#55) | 🔧 Audio intro breve |
| Demo: Constructor Prompts | #43 | 3.6 (#58) | 🔧 Audio intro breve |

### Bloque 4: "Práctica Guiada" (3 slides)
| Slide | Deck# | Origen | Estado |
|-------|:---:|:---:|:---:|
| 4.0 Portada | #44 | 4.0 (#59) | 🔧 Audio pendiente |
| 4.1 Generador prompts | #45 | 4.1 (#60) | 🔧 Audio pendiente |
| 4.2 Ejercicio grupos | #46 | 4.2 (#61) | 🔧 Audio pendiente |

### Bloque 5: "Cierre" (6 slides)
| Slide | Deck# | Origen | Estado |
|-------|:---:|:---:|:---:|
| 5.0 Portada | #47 | 5.0 (#62) | 🔧 Audio pendiente |
| 5.1 Modelo Sándwich | #48 | 5.1 (#63) | 🔧 Enriquecer audio (CRM + deliberación pre-algorítmica) |
| 5.2 Lo que nos llevamos | #49 | 5.2 (#64) | 🔧 Audio pendiente |
| 5.3 Test 1 | #50 | 5.3 (#65) | 🔧 Audio pendiente |
| 5.4 Test 2 | #51 | 5.4 (#66) | 🔧 Audio pendiente |
| 5.5 Gracias | #52 | 5.5 (#67) | 🔧 Audio pendiente |

---

## REFERENCIAS VERIFICADAS — añadir filas

| Ref | Slide nueva | Dato clave | Estado |
|-----|:---:|-----------|:---:|
| Callens 2026, Acta Clin Belg;1-12. DOI:10.1080/17843286.2026.2613903 | #35 | 4 elementos prompt, RTF+BRAIN, RAG mejora 9.8-16.3%, pooled 72% licensing | ✅ |
| Liu S 2025, JAMIA 32(4):605-615. DOI:10.1093/jamia/ocaf008 | #38 | 20 estudios, OR=1.35, RAG vs LLM base | ✅ |
| Zhao J 2025, BMC Med Inform Decis Mak 26:29. DOI:10.1186/s12911-025-03324-w | #32 | 23 incluidos, 14 pooled, SMD=-0.71, calidad comparable | ✅ |

---

## CORRECCIONES HTML PENDIENTES — actualizar

### Resueltas
- ~~Callens ref: "sin DOI canónico"~~ → DOI: 10.1080/17843286.2026.2613903 ✅
- ~~Liu source-note: "Nat Med"~~ → "JAMIA 2025;32(4):605-615" (aplicar al crear #38) ✅
- ~~Zhao año discrepancia~~ → 2025;26:29 es correcto ✅
- ~~Sub-bloque regulatorio 2B.18-20~~ → Resuelto en sesiones anteriores ✅
- ~~Slide 2B.14 duplicación~~ → ELIMINAR (duplica panel 3 de #27) ✅

### Nuevas pendientes (ejecución consolidación)
1. #31: subtítulo "15 minutos" → "~25 minutos"
2. #32: construir HTML fusionado (2 paneles + caveat Goodson)
3. #33: construir tabla HTML dominios (5 filas, verificar refs)
4. #34: imagen → tabla HTML (verificar refs Nguyen, Ilić, Var)
5. #35: imagen con erratas → HTML limpio (Callens + RECORD + determinista)
6. #36: construir slide Pirámide 5.0 + ecosistema (absorbe 3.1+3.2+2C.6+2C.7)
7. #37: migrar 3.5 GPTs/Gems a posición 2C
8. #38: fusionar RAG + Whitelisting, corregir Nat Med→JAMIA
9. #39: diferenciar visualmente de #29 (semáforo investigación vs consulta)
10. #40: reescribir síntesis alineada con 5 decisiones
11. #41-#43: simplificar portada Bloque 3, mantener demos
12. Eliminar 15 slides del deck HTML (ver lista en estructura_definitiva)
13. Bloque 2B pendientes: #17 PI→composite, #18 pie→JAMA Netw Open

---

## NOTAS PARA CONTINUIDAD — añadir

- Consolidación aprobada 2026-02-20. Documento maestro: estructura_definitiva_2C_5.md
- RECORD migra de Bloque 3 (demo) a Bloque 2C (método de prompting). Se practica en Bloque 4
- Pirámide 5.0 + catálogo herramientas migran de Bloque 3 a 2C
- GPTs/Gems migra de Bloque 3 a 2C
- Bloque 3 queda con SOLO 2 demos reales + portada
- "5 decisiones" = hilo conductor de 2C: dónde empezar, qué herramienta, cómo preguntar, cómo verificar, qué delegar
- Total presentación: 52 slides, ~114 min. Margen 6 min para imprevistos
- Abierto a nuevas slides con recursos prácticos si refuerzan didáctica (ajustar timing)
- Dato CoT 17.9%→58.1% (GSM8K) NO es clínico — buscar dato clínico o eliminar en #35
- Prioridad ejecución: #32 y #35 son las más complejas (HTML con paneles + fusiones múltiples)


## ACTUALIZACIONES 2026-02-20 (sesión 3)

- 2C.0 (deck #31): audio + HTML cerrados. Layout original conservado. Añadida barra navegadora 5 decisiones (Dónde empezar → Qué herramienta → Cómo preguntar → Cómo verificar → Qué delegar). Subtítulo actualizado. Tiempo: 15→~25 min. ~18s.

### Bloque 2C: "De la Evidencia a la Práctica" (actualización tabla estado)

| Slide | Deck# | Estado | Notas |
|-------|-------|--------|-------|
| 2C.0 Portada | 31 | ✅ | Barra 5 decisiones añadida. ~18s |

### TEXTOS DEFINITIVOS

---

### 2C.0 — Portada Bloque 2C (deck #31)

Hemos visto la evidencia. La hemos debatido, la hemos medido, la hemos puesto en perspectiva. Ahora toca lo concreto. En los próximos veinticinco minutos vamos a tomar cinco decisiones prácticas: dónde empezar, qué herramienta elegir, cómo preguntar, cómo verificar, y qué podemos delegar con seguridad. De la evidencia a vuestra consulta del lunes.



# Slide #33 — Aplicaciones clínicas por dominio
# Fecha: 2026-02-20
# Reemplaza: Dx precoz AP + Pediatría + Riesgo suicida + Educación (4 sections)
# Resultado neto: −3 slides

---

## AUDIO — Texto definitivo (~80s)

La IA no solo documenta. En esta tabla tenéis cinco dominios donde ya hay evidencia cuantitativa, y quiero que os fijéis en la columna de la derecha.

En neonatología, la detección de retinopatía del prematuro alcanza una efe-uno de cero con ochenta y nueve, y la predicción de hipoxemia perioperatoria un área bajo la curva de cero con ochenta y cinco. Son tareas de cribado con datos estructurados, donde la IA rinde bien.

En diagnóstico precoz, un sistema multi-agente para espondiloartritis consiguió sensibilidad de cero con noventa y cuatro en atención primaria. Interesante, pero es un estudio único en una patología concreta.

En salud mental, la detección de mensajes con riesgo suicida alcanza el noventa y nueve por ciento. Pero cuando hay que distinguir frustración de riesgo real, baja al ochenta y nueve. Esa diferencia entre detectar palabras y entender intención es exactamente lo que separa el cribado del juicio clínico.

Y en educación médica, los modelos generan preguntas de examen con calidad comparable a las de profesores. Pero fijaos: noventa y cuatro con cinco por ciento en preguntas tipo test, y variabilidad extrema en casos clínicos reales. Mismo patrón de siempre: tarea acotada, buen rendimiento. Juicio contextual, cae.

El patrón es claro: cuanto más estructurada la tarea y más lejos del juicio clínico, mejor rinde. Cuanto más cerca de la decisión sobre el paciente, más supervisión necesita. Eso es exactamente lo que cuantifica la siguiente slide.

---

## INSTRUCCIONES DE IMPLEMENTACIÓN

1. **Eliminar** las 4 `<section>` originales:
   - "Diagnóstico precoz AP"
   - "Pediatría"
   - "Riesgo suicida"
   - "Educación médica" (o "Educación")

2. **Si la slide de Caries sigue en el HTML**, eliminarla también (5ª eliminación)

3. **Insertar** la única `<section>` nueva

4. **Resultado neto:** −3 slides (o −4 si caries sigue)

---

## REFERENCIAS VERIFICADAS (según PubMed)

| Ref | DOI | PMID | Dato clave | Dominio | Estado |
|-----|-----|------|-----------|---------|--------|
| Zhang et al. BMJ Open Ophthalmol 2026 | 10.1136/bmjophth-2025-002385 | 41545231 | ROP screening, F1 0.89, AUC 0.90 | Neonatal | ✅ |
| Baek et al. PLoS ONE 2026 | 10.1371/journal.pone.0339276 | 41505469 | Hipoxemia periop, AUC 0.85 (0.83 ext) | Neonatal | ✅ |
| Xie et al. Lancet Digit Health 2025 | 10.1016/j.landig.2025.100926 | 41419365 | NeonatalBERT, AUPRC 0.291 | Neonatal | ✅ |
| Ji et al. npj Digit Med 2026 | 10.1038/s41746-026-02372-4 | 41571772 | Multi-agente espondiloartritis, Sens 0.94 | Dx precoz AP | ✅ |
| Qadir et al. JMIR Ment Health 2026 | 10.2196/76051 | 41576367 | 99% detección msg, 89% genuino | Salud mental | ✅ |
| Baskan et al. BMC Med Educ 2025 | 10.1186/s12909-025-08315-z | 41466246 | 94.5% MCQ, variabilidad en casos | Educación | ✅ |

---

## NOTAS

### ⚡ Ji et al. NO es pediatría
- El estudio es sobre espondilitis axial en adultos (reumatología)
- Las métricas (Sens 0.94, Acc 0.86) son del sistema SpAgents para axSpA
- Se mantiene en tabla como "Dx precoz AP" porque demuestra el concepto multi-agente en primaria
- Si esto incomoda, se puede sustituir por otro estudio pediátrico de Dx precoz

### Tabla con 4 filas (no 5)
- La estructura_definitiva preveía 5 filas incluyendo "Salud bucodental (caries)"
- Ernesto indica que esa slide ya fue sustituida → tabla queda con 4 filas
- Se puede añadir una 5ª fila si se identifica otro dominio con evidencia cuantitativa

### Xie (NeonatalBERT) no incluido en tabla visual
- AUPRC 0.291 es bajo en términos absolutos, difícil de contextualizar en una tabla rápida
- Se mantiene en la source-note por rigurosidad pero no se destaca como métrica principal
- En el audio NO se menciona (evitar dato que confunda más que aclare)

### Patrón narrativo
- La tabla NO es una lista de aplicaciones. Es una demostración visual del patrón "cribado > juicio"
- La columna "Nivel" (Cribado / Soporte / Solo investigación / Listo) es el dato clave
- El audio guía la lectura de derecha a izquierda: métrica → implicación


# Slide #34 — Matriz de Madurez Tecnológica
# Deck position: #34 | Código: 2C (sin número propio, tabla resumen)
# Fecha: 2026-02-20 | Estado: HTML + audio listos

---

## AUDIO DEFINITIVO (~80s)

Esta tabla es el resumen ejecutivo de todo lo que hemos visto. Cinco dominios, cinco niveles de madurez, y un patrón que a estas alturas ya debería sonaros.

En verde, lo que está listo para usar con supervisión: documentación clínica y educación. Zhao demostró que los resúmenes generados por IA tienen calidad comparable a los humanos, y Baskan que las preguntas de examen alcanzan el noventa y cuatro con cinco por ciento de precisión. Aquí la IA ya aporta valor neto.

En amarillo, lo que promete pero hay que verificar cada output. En diagnóstico de enfermedades raras pediátricas, Ilić y Sarajlija evaluaron dos modelos con cuarenta y cinco niños con displasias esqueléticas confirmadas genéticamente: los modelos alcanzaron el sesenta y dos al sesenta y cuatro por ciento de acierto en top tres, frente al ochenta y dos de los expertos. Útil como apoyo, no como sustituto. Y en investigación, la síntesis automatizada de literatura alcanza efe-uno de cero con noventa y dos a cero con noventa y ocho en cribado de artículos. Excelente para la fase mecánica, pero no para la evaluación crítica.

En rojo, salud mental. La detección de riesgo suicida en mensajes alcanza el noventa y nueve por ciento, pero distinguir frustración de riesgo real baja al ochenta y nueve. Solo investigación, nada clínico todavía.

El patrón se repite: cuanto más cerca de la decisión sobre el paciente, más lejos del uso autónomo. Ahora vamos a ver cómo hablarle a estas herramientas para sacarles el máximo partido.

---

## CAMBIOS RESPECTO A SLIDE ORIGINAL

1. **Imagen eliminada**: slide_matriz_madurez.jpg → tabla HTML nativa con refs como links
2. **source-note eliminado**: refs integradas en columna "Ref" de la tabla (evita superposición con player)
3. **Refs sustituidas**: Nguyen, Var, Mansoor (salud mental) no verificables en PubMed — probablemente generadas por NotebookLM
4. **Nuevas refs**: todas verificadas con DOI en el proyecto

## REFERENCIAS VERIFICADAS

| Ref | Dominio | Dato | PMID | DOI | Estado |
|-----|---------|------|------|-----|--------|
| Zhao 2025, BMC Med Inform Decis Mak 26:29 | Administrativo | 23 estudios, 14 pooled, SMD −0.71 | 41444884 | 10.1186/s12911-025-03324-w | ✅ Ya en #32 |
| Baskan 2025, BMC Med Educ | Educación | 94.5% MCQs, variabilidad en casos clínicos | 41466246 | 10.1186/s12909-025-08315-z | ✅ Ya en #33 |
| Ilić & Sarajlija 2025, Genes 16(7):762 | Diagnóstico | 45 niños displasias esqueléticas, ChatGPT 62.2%, DeepSeek 64.4% top-3, expertos 82.2%, κ=0.95 intermodelo | 40725418 | 10.3390/genes16070762 | ✅ NUEVO |
| Lee 2025, Value Health 28(11):1655-1664 | Investigación | A4SLR: F1 cribado 0.917-0.977, extracción 0.96-0.998 | — | 10.1016/j.jval.2025.08.002 | ✅ Ya en #29 |
| Qadir 2026, JMIR Ment Health | Salud mental | 99% detección riesgo suicida, 89% genuino | 41576367 | 10.2196/76051 | ✅ Ya en #33 |

### Refs originales NO verificables (NotebookLM)
- **Nguyen et al. (2025)** para Educación/Simplificación → No encontrado en PubMed ni Consensus. Sustituido por Baskan 2025
- **Var et al. (2025)** para Investigación/Síntesis → No encontrado en ninguna base de datos. Sustituido por Lee 2025
- **Mansoor et al. (2025)** para Salud Mental/Triaje → El Mansoor verificado (JMIRx Med) es de Dx rural Louisiana, no de salud mental. Sustituido por Qadir 2026

### Nota sobre Ilić & Sarajlija
Tienen DOS papers:
1. J Pers Med 2025;15(9):407 (PMID: 41003110) — Narrative review de IA en enfermedades raras pediátricas (sin métricas propias)
2. **Genes 2025;16(7):762 (PMID: 40725418)** — Estudio comparativo con 45 niños, métricas reales. ESTE es el que usamos ✅

---

## IMPLEMENTACIÓN

### Delta mínimo sobre HTML actual
Reemplazar el `<section>` completo (imagen + source-note) por la tabla HTML del archivo slide_34_html.html.

### Imagen liberada
- slide_matriz_madurez.jpg → libre como reserva

---

## NOTAS PARA CONTINUIDAD

- La tabla de #34 usa las mismas refs que #33 (Baskan, Qadir) y #32 (Zhao), más Lee de #29 e Ilić nuevo
- Ilić & Sarajlija: κ intermodelo = 0.95 (ChatGPT vs DeepSeek coinciden mucho entre sí, pero ambos lejos del experto) — dato potente para audio si hay tiempo
- El "534 refs" del source-note original es plausible como síntesis propia pero no verificable — eliminado
- Audio ~80s (la estructura lo exige: 5 dominios con explicación del patrón)
- Puente a #35 (Prompt Engineering) limpio


# Slide #35 v2 — Prompt Engineering clínico: la estructura lo cambia todo

## Estado: ✅ HTML + Audio v2 listos para revisión

---

## CAMBIOS v1 → v2

1. **Narrativa reordenada:** RECORD primero ("os proponemos un marco nemotécnico"), Callens después como validación con datos
2. **Datos Callens integrados:** RAG +10-16% precisión / −12-18% alucinaciones / 72% pooled / correlación inversa confianza-precisión
3. **Concepto determinismo:** conectado con "inestable" del título; Arriola-Montenegro como prueba de que estructura convierte lo impredecible en reproducible
4. **Refs como enlaces inline:** 🔗 junto al título de cada panel + enlace en la barra de impacto. Eliminado source-note solapado con barra audio
5. **Panel RECORD a la izquierda (hero):** prioridad visual al método accionable

---

## AUDIO NARRACIÓN v2 (~95s, ~225 palabras)

La diferencia entre una respuesta clínica útil y una peligrosa no está solo en el modelo de IA. Puede estar también en cómo le preguntas. Y aquí hay una idea clave: la IA generativa no es intrínsecamente determinista; no funciona como una calculadora clínica que, con la misma entrada, siempre da exactamente la misma salida. Es un sistema probabilístico que funciona generando texto paso a paso, con variabilidad. Por eso, pequeños cambios en la forma del prompt ( es decir, en cómo preguntas) pueden cambiar el camino de la respuesta y condicionar mucho el resultado. Sin estructura, esa variabilidad se nota más: la misma pregunta, formulada de forma ligeramente distinta, puede producir recomendaciones distintas. En medicina, eso es inaceptable.


Para darle solidez, os proponemos RECORD: un acrónimo mnemotécnico de seis pasos que estructura cualquier consulta clínica a la IA. Rol, Escenario, Contexto, Objetivo, Restricciones y Diseño de salida. La mayoría de marcos similares cubren los cuatro primeros. La diferencia de RECORD son las dos últimas letras: Restricciones —lo que la IA no debe hacer ni incluir— y Diseño —el formato exacto de la respuesta—. Esos dos elementos son los que convierten un prompt genérico en un prompt controlado. En el bloque cuatro lo practicaréis con casos pediátricos.

Callens, en una revisión narrativa publicada en Acta Clinica Belgica en dos mil veintiséis, confirma esta lógica y aporta datos relevantes. Por ejemplo: un metaanálisis de treinta y seis estudios, que midió cómo rinden los modelos de lenguaje en exámenes de licenciatura médica de diez países, encontró una precisión media del setenta y dos por ciento. Es decir, un aprobado raspado. Y aquí viene lo preocupante: según este estudio, los modelos que peor puntúan muestran, paradójicamente, más confianza en sus respuestas. La IA que más se equivoca puede parecer la más segura.

¿Se puede reducir esa inestabilidad? La Clínica Mayo muestra que sí. Arriola-Montenegro y colegas evaluaron seiscientos escenarios de dosificación de anemia en hemodiálisis, un dominio donde un error de dosis puede ser grave. Con prompts sueltos, sin estructura, la IA solo seguía el protocolo institucional en el treinta y dos por ciento de los casos. Recomendaba dosis inseguras y violaba tiempos de espera entre ajustes. Entonces codificaron las reglas del protocolo directamente en la estructura del prompt, paso a paso. Resultado: cien por cien de adherencia. Trescientos de trescientos. La misma IA, distinto prompt.

Ese es el mensaje de esta diapositiva: la estructura no elimina la incertidumbre del modelo, ni vuelve determinista un sistema que no lo es; pero sí puede convertir respuestas variables en respuestas más reproducibles, más auditables y más seguras.

---

## NOTAS TTS

- "Acta Clínica Bélgica" → pronunciación española del journal
- "nemotécnico" → natural en español
- Todos los porcentajes en letra
- "o uno, o tres, DeepSeek R-uno" → ELIMINADOS de v2 (simplificación; Context Engineering solo es relevante para audiencia técnica, ya se mencionó en slides anteriores 2C.4/2C.5 que ahora se absorben)
- Sin "último/más reciente/actual"

---

## REFERENCIAS VERIFICADAS

| Ref | Ubicación en slide | DOI/enlace | Estado |
|-----|-------------------|------------|--------|
| Barrera-Linares E. Método RECORD. Zenodo 2024 | Panel izq, título 🔗 | zenodo.org/records/16813419 | ✅ |
| Callens S. Acta Clin Belg. 2026;1-12 | Panel der, título 🔗 + caja datos | 10.1080/17843286.2026.2613903 | ✅ PMID:41524451 |
| Arriola-Montenegro et al. Front Artif Intell. 2025 | Barra impacto 🔗 | 10.3389/frai.2025.1728320 | ✅ Frontiers |

---

## DATOS CALLENS INCLUIDOS EN SLIDE (caja verde panel derecho)

| Dato | Fuente dentro del abstract |
|------|---------------------------|
| RAG +9.8-16.3% precisión (redondeado +10-16%) | "RAG improves accuracy by 9.8–16.3%" |
| RAG −11.8-18% alucinaciones (redondeado −12-18%) | "reducing hallucinations by 11.8–18%" |
| 72% pooled en licensing exams | "pooled LLM accuracy of 72% on medical licensing examinations" |
| Correlación inversa confianza-precisión | "inverse correlation between model confidence and accuracy" |

---

## LAYOUT VISUAL

```
┌─────────────────────────────────────────────────────────┐
│  Un prompt pobre genera MEDICINA INESTABLE               │
│  RECORD estructura · Callens valida · 32%→100%           │
├────────────────────────┬────────────────────────────────┤
│  📝 MÉTODO RECORD 🔗   │  ✅ VALIDACIÓN: 4 ELEMENTOS 🔗 │
│  ┌───┬───┬───┐         │  ① Rol                         │
│  │ R │ E │ C │         │  ② Contexto                    │
│  ├───┼───┼───┤         │  ③ Tarea                       │
│  │ O │ R │ D │         │  ④ Salida                      │
│  └───┴───┴───┘         │  ┌─────────────────────────┐   │
│  Restricciones + Diseño │  │ RAG +10-16%, −12-18%   │   │
│  = lo que otros no      │  │ 72% pooled, confianza↓  │   │
│  cubren                 │  └─────────────────────────┘   │
├─────────────────────────┴────────────────────────────────┤
│       32%  →  100%  adherencia · 300 casos 🔗            │
├──────────────────────────────────────────────────────────┤
│  🔧 Preview: Bloque 4, practicaremos RECORD              │
└──────────────────────────────────────────────────────────┘
```

---

## CONTENIDO ABSORBIDO (sin cambios vs v1)

| Slide original | Contenido absorbido | Cómo |
|----------------|---------------------|------|
| 2C.3 (#34 antiguo) | Callens 4 pasos | Panel derecho HTML |
| 2C.4 (#35 antiguo) | CoT, Few-shot, RAG, Self-consistency | RAG en datos Callens; resto absorbido en audio v1, simplificado en v2 |
| 2C.5 (#36 antiguo) | Context Engineering | Absorbido conceptualmente; no se menciona explícitamente en v2 |
| 2C.14 (#45 antiguo) | Dato 32%→100% | Barra de impacto inferior |
| 3.4 (#56 antiguo) | Método RECORD grid | Panel izquierdo hero |

---

## SLIDES A ELIMINAR DEL DECK HTML (sin cambios vs v1)

- 2C.3 (línea ~2745), 2C.4 (~2780), 2C.5 (~2864), 2C.14 (~3330), 3.4 (~3980)


### Slide #36 — Tu Caja de Herramientas (8.6)
- **Estado:** ✅ HTML v4 + Audio cerrado
- **Código anterior:** Fusión 3.1 (Pirámide placeholder) + 3.2 (Herramientas) + 2C.6 (Mapa) + 2C.7 (Ecosistema)
- **Assertion:** "No todas las IA son iguales: ayuda para la selección"
- **Subtitle:** "El 93% evalúa solo generalistas — tu caja tiene 3 niveles de confianza"
- **Imagen:** Ninguna (tabla HTML + glass-panel + aviso epistemológico)
- **Nota diseño:** Herramientas principales en negrita con enlace; complementarias en fuente menor (menos consolidadas, menor desarrollo clínico). La distinción visual indica jerarquía de madurez, no exclusión.
- **Nota secuencia:** Slide Pirámide 5.0 irá inmediatamente después. Audio hace puente explícito.

#### Audio #36 (~105s):

Ya sabemos qué funciona y cómo preguntar. Ahora toca la pregunta más práctica: ¿con qué herramienta? Y aquí hay un error frecuente que veo en colegas que empiezan: tratar a todas las inteligencias artificiales como si fueran lo mismo. No lo son. Y la diferencia importa clínicamente.

La tabla que tenéis en pantalla ordena las herramientas por nivel de confianza. Dejadme que la complemente con lo que no está escrito ahí.

En la fila de arriba, erre-a-ge clínico. Estas herramientas, Open Evidence, Perplexity, NotebookLM, tienen una arquitectura que impide que inventen. Primero buscan en fuentes verificadas, y solo después generan texto basándose exclusivamente en lo que han encontrado. No pueden fabricar un estudio que no existe.

En el medio, herramientas de investigación académica. Consensus, por ejemplo, busca en más de doscientos millones de artículos científicos reales y solo aplica inteligencia artificial después de la búsqueda. Elicit hace algo parecido: extrae datos de papers con una precisión validada del noventa y nueve coma cuatro por ciento. Y Scite os dice si un estudio ha sido apoyado o refutado por la literatura posterior. Ninguna de estas tres genera texto clínico: analizan lo que ya existe.

Y abajo, los modelos fundacionales: ChatGPT, Claude, Gemini, DeepSeek. Ojo, no son inútiles ni mucho menos. Todos pueden buscar en internet y citar fuentes. Gemini integra Google Search, ChatGPT tiene navegación web. Pero, y esto es clave, también pueden generar sin buscar. Y el usuario no siempre sabe en qué modo está. Por eso la confianza es variable y la supervisión no es opcional.

Ahora bien, un matiz importante que tenéis señalado en la slide. Que una herramienta cite su fuente no significa que esa fuente tenga peso metodológico. Una inteligencia artificial puede citar un artículo real de Nature y aun así producir una síntesis que no equivale a una revisión por pares. Trazabilidad no es lo mismo que evidencia preevaluada. Ese concepto lo vamos a desarrollar en la Pirámide cinco punto cero.

Un dato para poner esto en perspectiva. Según la revisión de Shool, que analizó setecientos sesenta y un estudios de cinco bases de datos, el noventa y tres por ciento evalúa modelos generalistas. De pediatría, solo diez estudios. De medicina de familia, dos. Sabemos mucho de ge-pe-te-cuatro en exámenes tipo test, y muy poco de cómo funcionan estas herramientas en nuestra consulta real.

Pero el panorama se mueve. En el panel inferior veis tres conceptos. Propietarios son modelos como ge-pe-te-cuatro o Gemini, que pertenecen a empresas y funcionan en sus servidores: tus datos salen de tu hospital. Open-source significa código público que puedes instalar en tu propio servidor: tus datos no salen. DeepSeek es open-source, y según el estudio de Sandmann, en ciento veinticinco casos clínicos rinde igual que los propietarios. Y especializados, como MedFound con ciento setenta y seis mil millones de parámetros, superan a los generalistas en ocho especialidades, pero casi nadie los evalúa todavía.

En la siguiente diapositiva vamos a ordenar todo esto visualmente con la Pirámide de Evidencia cinco punto cero adaptada a herramientas de inteligencia artificial.

#### Referencias verificadas:
| Ref | Cita completa | DOI | PMID | Dato clave |
|-----|---------------|-----|------|------------|
| Shool 2025 | Shool S et al. BMC Med Inform Decis Mak. 2025;25(1):117 | 10.1186/s12911-025-02954-4 | 40055694 | RS 761 estudios; 93.55% generalistas; pediatría 1.3% (10 est); familia 0.3% (2 est); accuracy 21.78% pero safety/bias raramente evaluados |
| Sandmann 2025 | Sandmann S et al. Nat Med. 2025;31(8):2546-2549 | 10.1038/s41591-025-03727-2 | 40267970 | DeepSeek V3/R1 open-source; 125 casos clínicos; rendimiento comparable a propietarios |
| Liu X 2025 | Liu X et al. Nat Med. 2025;31(3):932-942 | 10.1038/s41591-024-03416-6 | 39779927 | MedFound 176B parámetros; supera generalistas en 8 especialidades |

#### Notas de continuidad:
- ⚠️ Dos "Liu" distintos en la presentación: **Liu X** (MedFound, esta slide #36) vs **Liu S** (RAG meta-análisis, slide #38). No confundir.
- Dato "9.4% evalúa errores" (atribuido a Shool): no verificado en abstract ni full-text accesible. No incluido. Verificar en suplemento si se quiere recuperar.
- Dato "Elicit 99.4% precisión extracción": fuente = validación VDI/VDE publicada en web de Elicit (no paper peer-reviewed). Mencionado solo en audio, no en slide.
- Herramientas complementarias (fuente menor): Glass Health, Semantic Scholar, PubMed.ai, Scholar Lab, Copilot — menos consolidadas o con menor desarrollo clínico específico que las principales. Incluidas como alternativas útiles, no como recomendación primaria.

#### Puente → Pirámide 5.0:
Audio cierra con: "En la siguiente diapositiva vamos a ordenar todo esto visualmente con la Pirámide de Evidencia cinco punto cero adaptada a herramientas de inteligencia artificial."




### Slide #37 — Pirámide 5.0 + Ecosistema IA (iframe interactivo)
- **Deck #37 | Código: 2C.5 | Decisión 2: "Qué herramienta"**
- **Tipo:** iframe embebido (`data-background-iframe`), interactivo
- **URL producción:** `https://ernestobarrera.github.io/piramide-evidencia-ia.html?embed=1`
- **Audio src:** `aepap-2026/audios/367.webm`
- **Duración estimada:** ~60s (~150 palabras)
- **Ref:** Alper BS, Haynes RB. EBHC pyramid 5.0. Evid Based Med. 2016;21(4):123-5

**Texto del audio (formato párrafo):**

Acabáis de ver los tres niveles de confianza: erre a ge clínico, investigación académica y fundacional. Ahora vamos a profundizar con la herramienta interactiva que tenéis delante.

Esto es un modelo bidimensional. A la izquierda, la pirámide de evidencia cinco punto cero de Alper y Haynes: cinco niveles, desde los estudios originales en la base hasta los sistemas integrados en la historia clínica electrónica en la cúspide. A la derecha, las herramientas de inteligencia artificial clasificadas en la misma lógica de la tabla anterior, pero con más detalle: fundacionales frente a erre a ge.

La tesis sigue siendo la misma: trazabilidad no es evaluación crítica. Que una herramienta cite un artículo del ene i ye eme no significa que lo haya ponderado. Acceder a Cochrane no es producir una revisión Cochrane.

Explorad la interfaz. Al pasar el ratón por cada herramienta se iluminan los niveles de la pirámide a los que accede. Al hacer clic se abre su ficha: características, precio, mejor uso y precauciones. Los botones superiores explican la diferencia entre grounding y appraisal, la guía de evaluación crítica y las conclusiones prácticas.

Usad este mapa cuando volváis a la consulta y dudéis de con qué herramienta trabajar.

**Texto data-audio-text (una sola línea TTS):**

`Acabáis de ver los tres niveles de confianza: erre a ge clínico, investigación académica y fundacional. Ahora vamos a profundizar con la herramienta interactiva que tenéis delante. Esto es un modelo bidimensional. A la izquierda, la pirámide de evidencia cinco punto cero de Alper y Haynes: cinco niveles, desde los estudios originales en la base hasta los sistemas integrados en la historia clínica electrónica en la cúspide. A la derecha, las herramientas de inteligencia artificial clasificadas en la misma lógica de la tabla anterior, pero con más detalle: fundacionales frente a erre a ge. La tesis sigue siendo la misma: trazabilidad no es evaluación crítica. Que una herramienta cite un artículo del ene i ye eme no significa que lo haya ponderado. Acceder a Cochrane no es producir una revisión Cochrane. Explorad la interfaz. Al pasar el ratón por cada herramienta se iluminan los niveles de la pirámide a los que accede. Al hacer clic se abre su ficha: características, precio, mejor uso y precauciones. Los botones superiores explican la diferencia entre grounding y appraisal, la guía de evaluación crítica y las conclusiones prácticas. Usad este mapa cuando volváis a la consulta y dudéis de con qué herramienta trabajar.`

- **Puente desde #35:** de cómo preguntar (RECORD) → a con qué herramienta preguntar
- **Puente a #37:** de elegir herramienta genérica → personalizar con GPTs/Gems
- **Nota técnica:** Cookie banner de la fuente interfiere con plugin audio Reveal.js. Solución: añadir `?embed=1` a URL y suprimir banner en el JS de la página fuente.

# SLIDE #38 v2 — RAG + Whitelisting (fusión #47+#48 antiguos)
## Entregable 2026-02-21

---

## 1. CAMBIOS RESPECTO A v1

| Aspecto | v1 | v2 |
|---------|----|----|
| Layout | grid-2 (RAG izq + Whitelisting der) | RAG protagonista arriba + barra horizontal abajo |
| Diagrama RAG | Círculos pequeños (90px) | Círculos grandes (120-130px), réplica fiel de imagen original |
| Tipos de RAG | No incluidos | Mini-leyenda: Estricto / Híbrido / Sobre HCE |
| Whitelisting | Panel completo al 50% | Barra compacta horizontal con métricas en línea |
| Regla binaria | En subtitle (sin destacar) | Panel propio con ⚠️ icono rojo + fondo rojo tenue |
| Flechas | Verdes (--secondary) | Rojas (#ef4444), como en la imagen original |
| Audio | ~62s | ~72s (añadido párrafo sobre tipos de RAG) |

---

## 2. DELTA HTML

**Acción:** Reemplazar líneas 7999–8104 por el contenido de `slide38_v2.html`

---

## 3. GUION DE AUDIO — #38 v2 (~72s)

### Texto para markdown:

Erre-a-ge es la diferencia entre una i-a que inventa y una que busca antes de responder. El concepto es simple: en lugar de generar desde su entrenamiento, el modelo primero busca en fuentes que tú le proporcionas y genera solo a partir de lo que ha leído. El metaanálisis de Liu en yámia, veinte estudios, muestra mejora significativa: OR de uno con treinta y cinco comparado con ele-ele-emes base.

Pero no todos los erre-a-ge son iguales. En el extremo estricto tenéis NotebookLM: solo responde desde los documentos que le subes. En el otro, los modelos con búsqueda web como Perplexity o ChatGPT, que mezclan recuperación con su propio entrenamiento. Y luego está el erre-a-ge sobre historia clínica electrónica, que es lo que usan los sistemas de documentación ambiental como los que vimos antes. Cuanto más estricto, más seguro.

Y hay un segundo paso igual de importante: el whitelisting. Restringir las fuentes a guías profesionales sube la precisión del sesenta al setenta y ocho por ciento, dieciocho puntos. Incluir una sola fuente no profesional reduce las odds de acierto a la mitad.

La regla para vuestra consulta es binaria: si la herramienta no cita la fuente primaria verificable, no la uses en clínica.

---

## 4. DELTA PARA guiones_audio_definitivos_actualizado.md

### En tabla de estado Bloque 2C, sustituir fila #38:

```
| RAG + Whitelisting | #38 | ✅ | Fusión #47+#48. Imagen→HTML. Nat Med→JAMIA. Tipos RAG (estricto/híbrido/HCE). Regla binaria destacada. ~72s. |
```

### En sección AUDIO SCRIPTS, sustituir bloque #38:

```
### #38 — RAG + Whitelisting: la solución técnica (~72s)

**Assertion:** "En point-of-care, sin RAG no hay seguridad suficiente"

**Texto audio:**
Erre-a-ge es la diferencia entre una i-a que inventa y una que busca antes de responder. El concepto es simple: en lugar de generar desde su entrenamiento, el modelo primero busca en fuentes que tú le proporcionas y genera solo a partir de lo que ha leído. El metaanálisis de Liu en yámia, veinte estudios, muestra mejora significativa: OR de uno con treinta y cinco comparado con ele-ele-emes base.

Pero no todos los erre-a-ge son iguales. En el extremo estricto tenéis NotebookLM: solo responde desde los documentos que le subes. En el otro, los modelos con búsqueda web como Perplexity o ChatGPT, que mezclan recuperación con su propio entrenamiento. Y luego está el erre-a-ge sobre historia clínica electrónica, que es lo que usan los sistemas de documentación ambiental como los que vimos antes. Cuanto más estricto, más seguro.

Y hay un segundo paso igual de importante: el whitelisting. Restringir las fuentes a guías profesionales sube la precisión del sesenta al setenta y ocho por ciento, dieciocho puntos. Incluir una sola fuente no profesional reduce las odds de acierto a la mitad.

La regla para vuestra consulta es binaria: si la herramienta no cita la fuente primaria verificable, no la uses en clínica.

**Refs verificadas:**
- Liu S et al. JAMIA. 2025;32(4):605-615. DOI: 10.1093/jamia/ocaf008. (20 estudios, OR=1.35, RAG vs LLM base)
- Masanneck et al. J Med Internet Res 2025. DOI: 10.2196/79379. (Whitelisting: 60%→78%, OR 0.50 con fuente no profesional)

**Puente narrativo:** #37 (GPTs/Gems) → #38 (RAG + Whitelisting: cómo asegurar las fuentes) → #39 (Semáforo AP: qué delegar con todo esto). Conexión explícita con #32 (IA ambiental = RAG sobre HCE).
```

### Correcciones resueltas (mover de pendientes):

```
- ~~Liu source-note: "Nat Med"~~ → JAMIA 2025;32(4):605-615 ✅
- ~~slide_rag_estandar.jpg~~ → Diagrama HTML nativo ✅  
- ~~#38 fusión RAG+Whitelisting~~ → HTML + audio completados ✅
- ~~#38 Nat Med→JAMIA~~ → Aplicado (pendiente de memoria) ✅
```

---

## 5. NOTAS

- Audio pasa de ~62s a ~72s por el párrafo de tipos de RAG. Dentro del margen (target 70s en estructura_definitiva).
- La distinción estricto/híbrido/HCE conecta con #32 (IA ambiental usa RAG sobre HCE) y con #36 (Pirámide 5.0: los niveles de confianza dependen del tipo de RAG).
- Slides antiguas #47 y #48 del deck: listas para eliminar cuando confirmes.




En tabla de estado Bloque 2C, sustituir fila #39:
| Semáforo AP | #39 | ✅ | Imagen→HTML nativo. Cards verticales (diferencia visual con grid #29). Criterio: supervisión requerida. Barra diferenciadora explícita. Moulaei 2024 verificado. ~68s. |
En sección AUDIO SCRIPTS, añadir bloque #39:
### #39 — Semáforo AP: qué delegar y qué prohibir (~68s)

**Assertion:** "Tu consulta del lunes: qué adoptar, qué supervisar, qué evitar"

**Texto audio:**
En el bloque de evidencia vimos un semáforo para investigación. El criterio allí era: ¿puedo detectar el error antes de que cause daño? Este semáforo es distinto. Es para vuestra consulta del lunes, y el criterio es otro: ¿qué nivel de supervisión necesita esta tarea?

Luz verde: usar ahora. Administración, documentación clínica y borradores de información para familias. ¿Por qué verde? Porque son tareas donde el riesgo clínico directo es bajo, el ahorro de tiempo es alto, y la evidencia es la más sólida que hemos visto. Si el modelo redacta un informe de rutina o un borrador educativo, lo revisas en segundos y lo corriges si hace falta.

Luz amarilla: usar con cuidado. El modelo como segundo cerebro para diagnóstico diferencial complejo, y como apoyo en enfermedades raras. ¿Por qué amarillo? Porque aquí la i-a puede aportar valor real ampliando tu lista diagnóstica, pero solo si validas siempre con erre-a-ge contra fuentes profesionales. Nunca fiarse de la memoria del modelo.

Luz roja: evitar. Confianza ciega en lo que genera la i-a, y cualquier forma de sustitución del juicio clínico. No hay atajo aquí. La decisión clínica es tuya.

Fijaos en la diferencia: aquel semáforo clasificaba tareas de investigación. Este clasifica tareas de consulta. Complementarios, no redundantes.

**Refs verificadas:**
- Moulaei K et al. Int J Med Inform. 2024;188:105474. DOI: 10.1016/j.ijmedinf.2024.105474. (PMID: 38733640. Scoping review, 109 estudios GAI en salud)

**Puente narrativo:** #38 (RAG + Whitelisting) → #39 (Semáforo AP consulta) → #40 (Síntesis 5 mensajes)
Correcciones resueltas (mover de pendientes):
- ~~#39 imagen vs HTML~~ → HTML nativo con cards verticales ✅
- ~~#39 diferenciar de #29~~ → Diferenciación visual (cards vs grid) + barra explícita + criterio distinto ✅
- ~~Moulaei 2024 DOI~~ → 10.1016/j.ijmedinf.2024.105474 (PMID: 38733640) ✅

4. NOTAS DE DISEÑO
Diferenciación visual #29 vs #39
Elemento#29 (Investigación)#39 (Consulta AP)LayoutGrid horizontal 3 cols, compactoCards verticales con bordes redondeadosCabecerasFondo sólido color (verde/amarillo/rojo)Pill badges con icono emoji arribaTareasCon métricas numéricas (F1, κ, %)Sin métricas, solo tareas prácticasCriterioFila inferior "Error DETECTABLE"Fila inferior "Riesgo bajo / Valor real / Sin atajo"Assertion"Si la IA se equivoca, ¿puedes detectarlo?""Tu consulta del lunes: qué adoptar..."Barra extraNoSí: panel azul diferenciador explícitoIconosEmojis de semáforo 🟢🟡🔴FontAwesome temáticos (file-medical, brain, ghost)Refs8 refs (Lee, Asgari, Aktan...)1 ref (Moulaei scoping review)
Imagen eliminable

slide_semaforo_ap.jpg → PUEDE ELIMINARSE del directorio de assets cuando confirmes que el HTML funciona correctamente.

Nota sobre la barra diferenciadora
He incluido una barra azul en la parte inferior que dice explícitamente "#29 = investigación, #39 = consulta". Esto es útil durante la exposición pero podrías querer quitarla si prefieres que la diferenciación sea solo narrativa (audio). Tu decides.



---

# Slide #40 — Síntesis: 5 mensajes para el lunes (deck #40)
# Fecha: 2026-02-21
# Reemplaza: 2C.20 Síntesis (antigua #51)

## AUDIO — Texto definitivo (~55s)

Cinco mensajes. Sin datos nuevos, sin matices adicionales. Solo lo que os lleváis de este bloque para la consulta del lunes.

Primero: empezad por la documentación. Es donde la evidencia es más sólida y el riesgo más bajo. Automatizad la burocracia, revisad el resultado, y recuperad tiempo para el paciente.

Segundo: elegid herramienta por nivel de confianza, no por moda. La Pirámide cinco punto cero os da el criterio. No es lo mismo una búsqueda en Consensus que un chat abierto con un modelo generalista.

Tercero: estructurad cada consulta clínica a la IA. Rol, contexto, tarea, restricciones, salida. RECORD o Callens, da igual cuál, pero siempre con estructura. La diferencia entre el treinta y dos y el cien por cien de adherencia es exactamente eso.

Cuarto: exigid fuentes verificables. Si la herramienta no usa erre-a-ge o no podéis comprobar la referencia, no lo uséis para decisiones clínicas. Sin fuente, no hay seguridad.

Y quinto: delegad lo verde, supervisad lo amarillo, prohibid lo rojo. El semáforo de vuestra consulta no es el mismo que el de investigación. El criterio aquí es: si se equivoca, ¿puedo detectarlo antes de que afecte al paciente?

Con esto cerramos el bloque de aplicaciones. Ahora, veámoslo funcionar en directo.

## NOTAS TÉCNICAS
- Sin references en source-note (cierre conceptual)
- Bookend visual: barra de #31 con ✅ en cada paso (color accent)
- Puente a Bloque 3: "veámoslo funcionar en directo"
- TTS: "erre-a-ge" (RAG), "cinco punto cero" (5.0), "treinta y dos" / "cien por cien"
- Mensaje 5 con colores semáforo: verde #22c55e, amarillo #eab308, rojo #ef4444
- margin-bottom: 18px (evita superposición barra audio sin exceso)
- Números arábigos (1–5) en vez de Unicode circled para máxima compatibilidad

## TABLA ESTADO — actualizar fila #40

| Slide | Deck# | Estado | Notas |
|-------|-------|--------|-------|
| 2C.20 Síntesis | #40 | ✅ | Audio + HTML cerrados. 5 mensajes = 5 decisiones. Bookend ✅. ~55s |